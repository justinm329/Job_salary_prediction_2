{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "889abbcb-fb34-4701-8b42-ae5a242f3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "88aebd3f-9882-4a00-a140-c56a5c765c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Justi\\\\Bootcamp Course Work\\\\Github\\\\Job_salary_prediction_2'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c832b087-5e34-4712-a86a-493a88f98991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../Data/Train_rev1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb7429-a43b-4de8-b195-e39538ee9955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0330dbb4-0800-44ca-8765-d9d723410d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244768 entries, 0 to 244767\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   Id                  244768 non-null  int64 \n",
      " 1   Title               244767 non-null  object\n",
      " 2   FullDescription     244768 non-null  object\n",
      " 3   LocationRaw         244768 non-null  object\n",
      " 4   LocationNormalized  244768 non-null  object\n",
      " 5   ContractType        65442 non-null   object\n",
      " 6   ContractTime        180863 non-null  object\n",
      " 7   Company             212338 non-null  object\n",
      " 8   Category            244768 non-null  object\n",
      " 9   SalaryRaw           244768 non-null  object\n",
      " 10  SalaryNormalized    244768 non-null  int64 \n",
      " 11  SourceName          244767 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 22.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "078ab9d4-6e0a-40ed-ad32-cac15706d458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "Title                      1\n",
       "FullDescription            0\n",
       "LocationRaw                0\n",
       "LocationNormalized         0\n",
       "ContractType          179326\n",
       "ContractTime           63905\n",
       "Company                32430\n",
       "Category                   0\n",
       "SalaryRaw                  0\n",
       "SalaryNormalized           0\n",
       "SourceName                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on this those 3 features should be dropped before removing the null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "129683e5-4d7a-40e8-af21-fd49f31b1300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>27500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Engineering Systems Analyst   \n",
       "1                            Stress Engineer Glasgow   \n",
       "2                   Modelling and simulation analyst   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription LocationNormalized  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...            Dorking   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...            Glasgow   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...          Hampshire   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...             Surrey   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...             Surrey   \n",
       "\n",
       "           Category  SalaryNormalized  \n",
       "0  Engineering Jobs             25000  \n",
       "1  Engineering Jobs             30000  \n",
       "2  Engineering Jobs             30000  \n",
       "3  Engineering Jobs             27500  \n",
       "4  Engineering Jobs             25000  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns that we won't need, Company, ContractType, ContractTime, SalaryRaw, LocationRaw, ID\n",
    "new_df = df.drop(columns = [\"Company\", \"ContractType\", \"ContractTime\", \"SalaryRaw\", \"LocationRaw\", \"Id\", \"SourceName\"])\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d7d3a229-2d10-43f1-8257-b858f1c09016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244768"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "effebbcb-5667-4320-912f-ec1046c4fcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                 object\n",
       "FullDescription       object\n",
       "LocationNormalized    object\n",
       "Category              object\n",
       "SalaryNormalized       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes again\n",
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3ceaa2c3-d112-4139-b9f6-262e8f44bbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                 1\n",
       "FullDescription       0\n",
       "LocationNormalized    0\n",
       "Category              0\n",
       "SalaryNormalized      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many null values are in the new_df\n",
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "44d665ba-60c6-4cdd-99f7-cadcc6337f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the null values of this dataframe\n",
    "new_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "35e11d04-cefa-4bb9-af4c-63fd1dac9aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                 0\n",
       "FullDescription       0\n",
       "LocationNormalized    0\n",
       "Category              0\n",
       "SalaryNormalized      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7f270395-0e2b-4e3a-8fc6-f31fb2e59dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244767"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "e31a15bc-776d-44bc-9fa3-42502469a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = new_df.loc[:4000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1b319d8b-9298-4301-bb61-c3f32f1c1421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Justi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Justi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Justi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# Code to download corpora\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "a08ec559-3b8e-469b-8bf8-9609f3b2f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "492c0b40-ed86-4111-afad-440fde59743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "af127a8d-91a5-4be0-b877-23728391a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(article):\n",
    "    sw = set(stopwords.words('english'))\n",
    "    sw_addons = {\"k\", \"uk\",\"also\"} \n",
    "    # Substitute everything that is not a letter with an empty string\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    # we sub in an extra character for anything that is not a character from the\n",
    "    # above line of code\n",
    "    re_clean = regex.sub('', article)\n",
    "    # tokenize each word in the sentence\n",
    "    words = word_tokenize(re_clean)\n",
    "    # obtain the root word for each word \n",
    "    #stem = [stemmer.stem(word) for word in words]\n",
    "    lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # obtain an output that is all lowercase and not in the stop words\n",
    "    #output = [word.lower() for word in stem if word.lower() not in sw.union(sw_addons)]\n",
    "    output = [word.lower() for word in lem if word.lower() not in sw.union(sw_addons)]\n",
    "    output = ' '.join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "2617e7ce-9cca-420d-96f8-bbd3ebba0981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'engineering systems analyst dorking surrey salary client located dorking surrey looking engineering systems analyst client provides specialist software development keywords mathematical modelling risk analysis system modelling optimisation miser pioneeer engineering systems analyst dorking surrey salary'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function on sliced df to make sure it is correct\n",
    "clean_text(sliced_df[\"FullDescription\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "9342a623-55f1-4c67-9fec-a48a1166a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>CleanDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000</td>\n",
       "      <td>engineering systems analyst dorking surrey sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000</td>\n",
       "      <td>stress engineer glasgow salary currently looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000</td>\n",
       "      <td>mathematical modeller simulation analyst opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>27500</td>\n",
       "      <td>engineering systems analyst mathematical model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000</td>\n",
       "      <td>pioneer miser engineering systems analyst dork...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Engineering Systems Analyst   \n",
       "1                            Stress Engineer Glasgow   \n",
       "2                   Modelling and simulation analyst   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription LocationNormalized  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...            Dorking   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...            Glasgow   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...          Hampshire   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...             Surrey   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...             Surrey   \n",
       "\n",
       "           Category  SalaryNormalized  \\\n",
       "0  Engineering Jobs             25000   \n",
       "1  Engineering Jobs             30000   \n",
       "2  Engineering Jobs             30000   \n",
       "3  Engineering Jobs             27500   \n",
       "4  Engineering Jobs             25000   \n",
       "\n",
       "                                    CleanDescription  \n",
       "0  engineering systems analyst dorking surrey sal...  \n",
       "1  stress engineer glasgow salary currently looki...  \n",
       "2  mathematical modeller simulation analyst opera...  \n",
       "3  engineering systems analyst mathematical model...  \n",
       "4  pioneer miser engineering systems analyst dork...  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column that has the clean description of the job\n",
    "sliced_df['CleanDescription'] = sliced_df['FullDescription'].apply(clean_text)\n",
    "sliced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "f9109f5d-005d-47e8-bf9e-d85a53a2592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apply</th>\n",
       "      <th>area</th>\n",
       "      <th>based</th>\n",
       "      <th>candidate</th>\n",
       "      <th>care</th>\n",
       "      <th>client</th>\n",
       "      <th>company</th>\n",
       "      <th>contact</th>\n",
       "      <th>currently</th>\n",
       "      <th>cv</th>\n",
       "      <th>...</th>\n",
       "      <th>service</th>\n",
       "      <th>skill</th>\n",
       "      <th>staff</th>\n",
       "      <th>successful</th>\n",
       "      <th>support</th>\n",
       "      <th>team</th>\n",
       "      <th>time</th>\n",
       "      <th>training</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   apply  area  based  candidate  care  client  company  contact  currently  \\\n",
       "0      0     0      0          0     0       2        0        0          0   \n",
       "1      0     1      0          0     0       0        0        0          1   \n",
       "2      0     0      0          3     0       6        0        0          0   \n",
       "3      0     0      0          0     0       1        0        0          0   \n",
       "4      0     0      0          0     0       1        0        0          0   \n",
       "\n",
       "   cv  ...  service  skill  staff  successful  support  team  time  training  \\\n",
       "0   0  ...        0      0      0           0        0     0     0         0   \n",
       "1   0  ...        0      2      0           0        1     3     0         0   \n",
       "2   0  ...        0      3      0           3        1     0     1         0   \n",
       "3   0  ...        0      0      0           1        0     0     0         0   \n",
       "4   0  ...        0      0      0           0        0     0     0         0   \n",
       "\n",
       "   work  working  \n",
       "0     0        0  \n",
       "1     1        2  \n",
       "2     2        3  \n",
       "3     0        0  \n",
       "4     0        0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the COUNT for the working corpus.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",min_df=.25)\n",
    "count_vectorizer = vectorizer.fit_transform(sliced_df[\"CleanDescription\"])\n",
    "words_df = pd.DataFrame(count_vectorizer.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "9e9cf6c5-5e9d-472a-9165-50ded0390a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_2 = words_df.replace(list(range(1,100)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "2a0bc67b-d667-4734-bb7f-42d5f6ef546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apply</th>\n",
       "      <th>area</th>\n",
       "      <th>based</th>\n",
       "      <th>candidate</th>\n",
       "      <th>care</th>\n",
       "      <th>client</th>\n",
       "      <th>company</th>\n",
       "      <th>contact</th>\n",
       "      <th>currently</th>\n",
       "      <th>cv</th>\n",
       "      <th>...</th>\n",
       "      <th>service</th>\n",
       "      <th>skill</th>\n",
       "      <th>staff</th>\n",
       "      <th>successful</th>\n",
       "      <th>support</th>\n",
       "      <th>team</th>\n",
       "      <th>time</th>\n",
       "      <th>training</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      apply  area  based  candidate  care  client  company  contact  \\\n",
       "0         0     0      0          0     0       1        0        0   \n",
       "1         0     1      0          0     0       0        0        0   \n",
       "2         0     0      0          1     0       1        0        0   \n",
       "3         0     0      0          0     0       1        0        0   \n",
       "4         0     0      0          0     0       1        0        0   \n",
       "...     ...   ...    ...        ...   ...     ...      ...      ...   \n",
       "3495      0     0      0          0     0       1        1        0   \n",
       "3496      0     0      0          0     0       1        0        1   \n",
       "3497      1     0      1          0     0       0        1        1   \n",
       "3498      0     0      1          0     0       0        0        1   \n",
       "3499      1     0      0          0     0       1        1        1   \n",
       "\n",
       "      currently  cv  ...  service  skill  staff  successful  support  team  \\\n",
       "0             0   0  ...        0      0      0           0        0     0   \n",
       "1             1   0  ...        0      1      0           0        1     1   \n",
       "2             0   0  ...        0      1      0           1        1     0   \n",
       "3             0   0  ...        0      0      0           1        0     0   \n",
       "4             0   0  ...        0      0      0           0        0     0   \n",
       "...         ...  ..  ...      ...    ...    ...         ...      ...   ...   \n",
       "3495          0   0  ...        1      1      0           0        1     1   \n",
       "3496          0   0  ...        1      1      1           0        1     1   \n",
       "3497          0   1  ...        0      0      0           0        0     0   \n",
       "3498          0   1  ...        0      0      0           0        0     0   \n",
       "3499          0   0  ...        0      1      0           0        0     1   \n",
       "\n",
       "      time  training  work  working  \n",
       "0        0         0     0        0  \n",
       "1        0         0     1        1  \n",
       "2        1         0     1        1  \n",
       "3        0         0     0        0  \n",
       "4        0         0     0        0  \n",
       "...    ...       ...   ...      ...  \n",
       "3495     1         0     1        1  \n",
       "3496     1         1     1        1  \n",
       "3497     0         0     0        0  \n",
       "3498     0         0     0        0  \n",
       "3499     0         0     0        0  \n",
       "\n",
       "[3500 rows x 50 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "ca9df5be-cab5-414a-a9f2-9b0f6d72d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now set the vectorizer on the CleanDescription column and store it in a new variable\n",
    "#tf_idf_2 = vectorizer.fit_transform(sliced_df['CleanDescription'])\n",
    "# we now want to set the tf_idf to a dataframe\n",
    "#tf_score_df_2 = pd.DataFrame(tf_idf_2.toarray(), columns = vectorizer.get_feature_names())\n",
    "#tf_score_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "1e2ba8b7-f2fe-474d-b051-883d476debe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>CleanDescription</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wide</th>\n",
       "      <th>willing</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>workplace</th>\n",
       "      <th>written</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>engineering systems analyst dorking surrey sal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>stress engineer glasgow salary currently looki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>mathematical modeller simulation analyst opera...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>27500.0</td>\n",
       "      <td>engineering systems analyst mathematical model...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>pioneer miser engineering systems analyst dork...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Engineering Systems Analyst   \n",
       "1                            Stress Engineer Glasgow   \n",
       "2                   Modelling and simulation analyst   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription LocationNormalized  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...            Dorking   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...            Glasgow   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...          Hampshire   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...             Surrey   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...             Surrey   \n",
       "\n",
       "           Category  SalaryNormalized  \\\n",
       "0  Engineering Jobs           25000.0   \n",
       "1  Engineering Jobs           30000.0   \n",
       "2  Engineering Jobs           30000.0   \n",
       "3  Engineering Jobs           27500.0   \n",
       "4  Engineering Jobs           25000.0   \n",
       "\n",
       "                                    CleanDescription  ability  able  access  \\\n",
       "0  engineering systems analyst dorking surrey sal...      0.0   0.0     0.0   \n",
       "1  stress engineer glasgow salary currently looki...      0.0   0.0     0.0   \n",
       "2  mathematical modeller simulation analyst opera...      1.0   0.0     0.0   \n",
       "3  engineering systems analyst mathematical model...      0.0   0.0     1.0   \n",
       "4  pioneer miser engineering systems analyst dork...      0.0   0.0     0.0   \n",
       "\n",
       "   accommodation  ...  white  wide  willing  work  worker  workers  working  \\\n",
       "0            0.0  ...    0.0   0.0      0.0   0.0     0.0      0.0      0.0   \n",
       "1            0.0  ...    0.0   0.0      0.0   1.0     0.0      0.0      1.0   \n",
       "2            0.0  ...    0.0   0.0      0.0   1.0     0.0      0.0      1.0   \n",
       "3            0.0  ...    0.0   0.0      0.0   0.0     0.0      0.0      0.0   \n",
       "4            0.0  ...    0.0   0.0      0.0   0.0     0.0      0.0      0.0   \n",
       "\n",
       "   workplace  written  year  \n",
       "0        0.0      0.0   0.0  \n",
       "1        0.0      1.0   0.0  \n",
       "2        0.0      1.0   1.0  \n",
       "3        0.0      0.0   0.0  \n",
       "4        0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([sliced_df, filtered_df], axis = 1)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "fdab4219-9be3-42dd-ba8a-824514f86d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                   1\n",
       "FullDescription         1\n",
       "LocationNormalized      1\n",
       "Category                1\n",
       "SalaryNormalized        1\n",
       "                     ... \n",
       "workers               501\n",
       "working               501\n",
       "workplace             501\n",
       "written               501\n",
       "year                  501\n",
       "Length: 400, dtype: int64"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "d94299d3-23b5-485c-9626-84c7abb9d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "2b07103b-4f85-4822-a4fd-927f04e3bb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>accurate</th>\n",
       "      <th>achieve</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wide</th>\n",
       "      <th>willing</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>workplace</th>\n",
       "      <th>written</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>27500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category  SalaryNormalized  ability  able  access  accommodation  \\\n",
       "0  Engineering Jobs           25000.0      0.0   0.0     0.0            0.0   \n",
       "1  Engineering Jobs           30000.0      0.0   0.0     0.0            0.0   \n",
       "2  Engineering Jobs           30000.0      1.0   0.0     0.0            0.0   \n",
       "3  Engineering Jobs           27500.0      0.0   0.0     1.0            0.0   \n",
       "4  Engineering Jobs           25000.0      0.0   0.0     0.0            0.0   \n",
       "\n",
       "   accurate  achieve  act  acting  ...  white  wide  willing  work  worker  \\\n",
       "0       0.0      0.0  0.0     0.0  ...    0.0   0.0      0.0   0.0     0.0   \n",
       "1       0.0      0.0  0.0     0.0  ...    0.0   0.0      0.0   1.0     0.0   \n",
       "2       0.0      0.0  0.0     0.0  ...    0.0   0.0      0.0   1.0     0.0   \n",
       "3       0.0      0.0  0.0     0.0  ...    0.0   0.0      0.0   0.0     0.0   \n",
       "4       0.0      0.0  0.0     0.0  ...    0.0   0.0      0.0   0.0     0.0   \n",
       "\n",
       "   workers  working  workplace  written  year  \n",
       "0      0.0      0.0        0.0      0.0   0.0  \n",
       "1      0.0      1.0        0.0      1.0   0.0  \n",
       "2      0.0      1.0        0.0      1.0   1.0  \n",
       "3      0.0      0.0        0.0      0.0   0.0  \n",
       "4      0.0      0.0        0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the 2 description columns as we no longer need them\n",
    "combined_df = combined_df.drop(columns = [\"FullDescription\", \"CleanDescription\", \"Title\", \"LocationNormalized\"])\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ebab8932-e8b1-41d3-ae18-d2ee53450448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>accurate</th>\n",
       "      <th>achieve</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>active</th>\n",
       "      <th>...</th>\n",
       "      <th>Category_Manufacturing Jobs</th>\n",
       "      <th>Category_Other/General Jobs</th>\n",
       "      <th>Category_PR, Advertising &amp; Marketing Jobs</th>\n",
       "      <th>Category_Property Jobs</th>\n",
       "      <th>Category_Retail Jobs</th>\n",
       "      <th>Category_Sales Jobs</th>\n",
       "      <th>Category_Scientific &amp; QA Jobs</th>\n",
       "      <th>Category_Teaching Jobs</th>\n",
       "      <th>Category_Trade &amp; Construction Jobs</th>\n",
       "      <th>Category_Travel Jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalaryNormalized  ability  able  access  accommodation  accurate  achieve  \\\n",
       "0           25000.0      0.0   0.0     0.0            0.0       0.0      0.0   \n",
       "1           30000.0      0.0   0.0     0.0            0.0       0.0      0.0   \n",
       "2           30000.0      1.0   0.0     0.0            0.0       0.0      0.0   \n",
       "3           27500.0      0.0   0.0     1.0            0.0       0.0      0.0   \n",
       "4           25000.0      0.0   0.0     0.0            0.0       0.0      0.0   \n",
       "\n",
       "   act  acting  active  ...  Category_Manufacturing Jobs  \\\n",
       "0  0.0     0.0     0.0  ...                            0   \n",
       "1  0.0     0.0     0.0  ...                            0   \n",
       "2  0.0     0.0     0.0  ...                            0   \n",
       "3  0.0     0.0     0.0  ...                            0   \n",
       "4  0.0     0.0     0.0  ...                            0   \n",
       "\n",
       "   Category_Other/General Jobs  Category_PR, Advertising & Marketing Jobs  \\\n",
       "0                            0                                          0   \n",
       "1                            0                                          0   \n",
       "2                            0                                          0   \n",
       "3                            0                                          0   \n",
       "4                            0                                          0   \n",
       "\n",
       "   Category_Property Jobs  Category_Retail Jobs  Category_Sales Jobs  \\\n",
       "0                       0                     0                    0   \n",
       "1                       0                     0                    0   \n",
       "2                       0                     0                    0   \n",
       "3                       0                     0                    0   \n",
       "4                       0                     0                    0   \n",
       "\n",
       "   Category_Scientific & QA Jobs  Category_Teaching Jobs  \\\n",
       "0                              0                       0   \n",
       "1                              0                       0   \n",
       "2                              0                       0   \n",
       "3                              0                       0   \n",
       "4                              0                       0   \n",
       "\n",
       "   Category_Trade & Construction Jobs  Category_Travel Jobs  \n",
       "0                                   0                     0  \n",
       "1                                   0                     0  \n",
       "2                                   0                     0  \n",
       "3                                   0                     0  \n",
       "4                                   0                     0  \n",
       "\n",
       "[5 rows x 421 columns]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use get dummies to turn the category columns into number columns\n",
    "encoded_df = pd.get_dummies(combined_df)\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "9eb8de85-22fb-42d6-9cd1-5af1672d55a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into X and y\n",
    "X = encoded_df.drop(columns = [\"SalaryNormalized\"])\n",
    "y = encoded_df[\"SalaryNormalized\"].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "0e02b06b-34ff-43d9-b4d2-1d822eec91e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 420)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the shape of each data set\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "ef569c74-18d9-4ebe-82f1-2acee3038ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "c8433f6b-e0ba-4ad5-979d-2f0dba9e9c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 1)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "a6444fb0-85e9-4cb5-ba4a-9dff5049f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import train test split to split the data up\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "7dff7872-9982-4362-b469-4a853c9b2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "b942cd30-67c1-4c29-aa87-4b4db92b7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the training data\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "aa55b56b-906b-4f8a-b46a-662e2d61b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PCA for demionality reduction, we have alot of columns so lets condense them down\n",
    "#from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "114cb0e8-7e6f-41a3-afac-136222486e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters for the number of components\n",
    "#pca = PCA(n_components=4)\n",
    "# fit_transform X_train and X_test to pca\n",
    "#X_pca_train = pca.fit_transform(X_train_scaled)\n",
    "#X_pca_test = pca.fit_transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "0c3a7dfb-a186-498c-a37c-e47e92a38f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "1ff6b48c-b6f7-4909-bc4c-d699c72c536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "793c9931-68ab-414c-8db2-74264d6c0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators= 2000, min_samples_split = 3, min_samples_leaf=1, max_features= \"auto\", max_depth = 45, random_state = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "c0a1d2db-0ce8-4b0e-93cb-cb4360d23911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=45, min_samples_split=3, n_estimators=2000,\n",
       "                      random_state=78)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the random forest regressor to the x_train and y _train\n",
    "rfr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "a4393140-f615-439c-907b-3549a9266b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8820532852745349\n",
      "Test score: 0.29041517536640715\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {rfr.score(X_train_scaled, y_train)}')\n",
    "print(f\"Test score: {rfr.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "8d6d116a-7a86-4873-b229-3286cbc9ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "3450d0de-345c-416f-88eb-c38ce199ed6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13156.044947644188"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "7a004e07-3899-43a6-99fd-f4f40578b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the random forest is not producing the results I want\n",
    "# I will try to build a Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "64383894-7f3b-4d5d-b020-2e3d8ba57887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "5e2270a5-8f8c-43c8-bcf6-95b7fd30cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to define the number of hidden nodes and input features\n",
    "# start with a shallow network and expand from there\n",
    "# I am going to start with the number of columns as the input features\n",
    "number_input_columns = X.shape[1]\n",
    "number_hidden_nodes = (X.shape[1]/2)\n",
    "# Create NN\n",
    "neural_network = Sequential()\n",
    "\n",
    "# create the hidden latter\n",
    "neural_network.add(Dense(units = number_hidden_nodes, input_dim = number_input_columns, activation = \"relu\", kernel_initializer='normal' ))\n",
    "# create output layer\n",
    "neural_network.add(Dense(units = number_hidden_nodes/2,  activation = \"relu\", kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "d6bb37de-8953-4a05-9fa2-7a20a8e98200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210.0"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "e18a72bd-7cf0-4082-8c3c-d49deb615f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 210)               88410     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 105)               22155     \n",
      "=================================================================\n",
      "Total params: 110,565\n",
      "Trainable params: 110,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neural_network.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "1c6ab15e-9a4d-47d6-bc99-9de44339c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2e406-8df5-4a5d-9b5b-6184eb902c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "42fccafc-981b-4729-9fd7-fd0d638e2221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50/50 [==============================] - 5s 13ms/step - loss: 30926.1016 - mean_absolute_error: 30926.1016 - val_loss: 30446.6289 - val_mean_absolute_error: 30446.6289\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 30446.62891, saving model to Weights-001--30446.62891.hdf5\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 30908.2695 - mean_absolute_error: 30908.2695 - val_loss: 30417.2090 - val_mean_absolute_error: 30417.2090\n",
      "\n",
      "Epoch 00002: val_loss improved from 30446.62891 to 30417.20898, saving model to Weights-002--30417.20898.hdf5\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 30860.5879 - mean_absolute_error: 30860.5879 - val_loss: 30354.2461 - val_mean_absolute_error: 30354.2461\n",
      "\n",
      "Epoch 00003: val_loss improved from 30417.20898 to 30354.24609, saving model to Weights-003--30354.24609.hdf5\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 30774.2715 - mean_absolute_error: 30774.2715 - val_loss: 30252.8418 - val_mean_absolute_error: 30252.8418\n",
      "\n",
      "Epoch 00004: val_loss improved from 30354.24609 to 30252.84180, saving model to Weights-004--30252.84180.hdf5\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 30464.0723 - mean_absolute_error: 30464.072 - 0s 2ms/step - loss: 30647.1406 - mean_absolute_error: 30647.1406 - val_loss: 30112.9902 - val_mean_absolute_error: 30112.9902\n",
      "\n",
      "Epoch 00005: val_loss improved from 30252.84180 to 30112.99023, saving model to Weights-005--30112.99023.hdf5\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 30480.1680 - mean_absolute_error: 30480.1680 - val_loss: 29934.4648 - val_mean_absolute_error: 29934.4648\n",
      "\n",
      "Epoch 00006: val_loss improved from 30112.99023 to 29934.46484, saving model to Weights-006--29934.46484.hdf5\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 30272.9180 - mean_absolute_error: 30272.9180 - val_loss: 29718.7695 - val_mean_absolute_error: 29718.7695\n",
      "\n",
      "Epoch 00007: val_loss improved from 29934.46484 to 29718.76953, saving model to Weights-007--29718.76953.hdf5\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 30027.3984 - mean_absolute_error: 30027.3984 - val_loss: 29470.1934 - val_mean_absolute_error: 29470.1934\n",
      "\n",
      "Epoch 00008: val_loss improved from 29718.76953 to 29470.19336, saving model to Weights-008--29470.19336.hdf5\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 29744.3652 - mean_absolute_error: 29744.3652 - val_loss: 29184.0273 - val_mean_absolute_error: 29184.0273\n",
      "\n",
      "Epoch 00009: val_loss improved from 29470.19336 to 29184.02734, saving model to Weights-009--29184.02734.hdf5\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 29422.8965 - mean_absolute_error: 29422.8965 - val_loss: 28860.7695 - val_mean_absolute_error: 28860.7695\n",
      "\n",
      "Epoch 00010: val_loss improved from 29184.02734 to 28860.76953, saving model to Weights-010--28860.76953.hdf5\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 29066.9531 - mean_absolute_error: 29066.9531 - val_loss: 28508.5625 - val_mean_absolute_error: 28508.5625\n",
      "\n",
      "Epoch 00011: val_loss improved from 28860.76953 to 28508.56250, saving model to Weights-011--28508.56250.hdf5\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 28677.1582 - mean_absolute_error: 28677.1582 - val_loss: 28120.9121 - val_mean_absolute_error: 28120.9121\n",
      "\n",
      "Epoch 00012: val_loss improved from 28508.56250 to 28120.91211, saving model to Weights-012--28120.91211.hdf5\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 28251.8066 - mean_absolute_error: 28251.8066 - val_loss: 27701.6211 - val_mean_absolute_error: 27701.6211\n",
      "\n",
      "Epoch 00013: val_loss improved from 28120.91211 to 27701.62109, saving model to Weights-013--27701.62109.hdf5\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 27794.2598 - mean_absolute_error: 27794.2598 - val_loss: 27251.4102 - val_mean_absolute_error: 27251.4102\n",
      "\n",
      "Epoch 00014: val_loss improved from 27701.62109 to 27251.41016, saving model to Weights-014--27251.41016.hdf5\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 27303.9297 - mean_absolute_error: 27303.9297 - val_loss: 26772.3027 - val_mean_absolute_error: 26772.3027\n",
      "\n",
      "Epoch 00015: val_loss improved from 27251.41016 to 26772.30273, saving model to Weights-015--26772.30273.hdf5\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 26779.1445 - mean_absolute_error: 26779.1445 - val_loss: 26259.8574 - val_mean_absolute_error: 26259.8574\n",
      "\n",
      "Epoch 00016: val_loss improved from 26772.30273 to 26259.85742, saving model to Weights-016--26259.85742.hdf5\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 26223.6230 - mean_absolute_error: 26223.6230 - val_loss: 25716.5547 - val_mean_absolute_error: 25716.5547\n",
      "\n",
      "Epoch 00017: val_loss improved from 26259.85742 to 25716.55469, saving model to Weights-017--25716.55469.hdf5\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 25636.8496 - mean_absolute_error: 25636.8496 - val_loss: 25148.2285 - val_mean_absolute_error: 25148.2285\n",
      "\n",
      "Epoch 00018: val_loss improved from 25716.55469 to 25148.22852, saving model to Weights-018--25148.22852.hdf5\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 25021.2266 - mean_absolute_error: 25021.2266 - val_loss: 24548.9199 - val_mean_absolute_error: 24548.9199\n",
      "\n",
      "Epoch 00019: val_loss improved from 25148.22852 to 24548.91992, saving model to Weights-019--24548.91992.hdf5\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 24371.2422 - mean_absolute_error: 24371.2422 - val_loss: 23922.0547 - val_mean_absolute_error: 23922.0547\n",
      "\n",
      "Epoch 00020: val_loss improved from 24548.91992 to 23922.05469, saving model to Weights-020--23922.05469.hdf5\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 23692.0527 - mean_absolute_error: 23692.0527 - val_loss: 23264.4004 - val_mean_absolute_error: 23264.4004\n",
      "\n",
      "Epoch 00021: val_loss improved from 23922.05469 to 23264.40039, saving model to Weights-021--23264.40039.hdf5\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 22989.8789 - mean_absolute_error: 22989.8789 - val_loss: 22608.2598 - val_mean_absolute_error: 22608.2598\n",
      "\n",
      "Epoch 00022: val_loss improved from 23264.40039 to 22608.25977, saving model to Weights-022--22608.25977.hdf5\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 22278.4883 - mean_absolute_error: 22278.4883 - val_loss: 21941.8359 - val_mean_absolute_error: 21941.8359\n",
      "\n",
      "Epoch 00023: val_loss improved from 22608.25977 to 21941.83594, saving model to Weights-023--21941.83594.hdf5\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 21550.6660 - mean_absolute_error: 21550.6660 - val_loss: 21268.8926 - val_mean_absolute_error: 21268.8926\n",
      "\n",
      "Epoch 00024: val_loss improved from 21941.83594 to 21268.89258, saving model to Weights-024--21268.89258.hdf5\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 20832.4980 - mean_absolute_error: 20832.4980 - val_loss: 20614.2617 - val_mean_absolute_error: 20614.2617\n",
      "\n",
      "Epoch 00025: val_loss improved from 21268.89258 to 20614.26172, saving model to Weights-025--20614.26172.hdf5\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 20129.4961 - mean_absolute_error: 20129.4961 - val_loss: 19965.9473 - val_mean_absolute_error: 19965.9473\n",
      "\n",
      "Epoch 00026: val_loss improved from 20614.26172 to 19965.94727, saving model to Weights-026--19965.94727.hdf5\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 19445.0527 - mean_absolute_error: 19445.0527 - val_loss: 19358.3652 - val_mean_absolute_error: 19358.3652\n",
      "\n",
      "Epoch 00027: val_loss improved from 19965.94727 to 19358.36523, saving model to Weights-027--19358.36523.hdf5\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 18823.8359 - mean_absolute_error: 18823.8359 - val_loss: 18802.2109 - val_mean_absolute_error: 18802.2109\n",
      "\n",
      "Epoch 00028: val_loss improved from 19358.36523 to 18802.21094, saving model to Weights-028--18802.21094.hdf5\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 18254.3027 - mean_absolute_error: 18254.3027 - val_loss: 18278.0879 - val_mean_absolute_error: 18278.0879\n",
      "\n",
      "Epoch 00029: val_loss improved from 18802.21094 to 18278.08789, saving model to Weights-029--18278.08789.hdf5\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 17721.6465 - mean_absolute_error: 17721.6465 - val_loss: 17785.0957 - val_mean_absolute_error: 17785.0957\n",
      "\n",
      "Epoch 00030: val_loss improved from 18278.08789 to 17785.09570, saving model to Weights-030--17785.09570.hdf5\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 17230.1191 - mean_absolute_error: 17230.1191 - val_loss: 17319.8867 - val_mean_absolute_error: 17319.8867\n",
      "\n",
      "Epoch 00031: val_loss improved from 17785.09570 to 17319.88672, saving model to Weights-031--17319.88672.hdf5\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 16772.6953 - mean_absolute_error: 16772.6953 - val_loss: 16895.3398 - val_mean_absolute_error: 16895.3398\n",
      "\n",
      "Epoch 00032: val_loss improved from 17319.88672 to 16895.33984, saving model to Weights-032--16895.33984.hdf5\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 16341.0771 - mean_absolute_error: 16341.0771 - val_loss: 16499.6035 - val_mean_absolute_error: 16499.6035\n",
      "\n",
      "Epoch 00033: val_loss improved from 16895.33984 to 16499.60352, saving model to Weights-033--16499.60352.hdf5\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 15931.7344 - mean_absolute_error: 15931.7344 - val_loss: 16130.1699 - val_mean_absolute_error: 16130.1699\n",
      "\n",
      "Epoch 00034: val_loss improved from 16499.60352 to 16130.16992, saving model to Weights-034--16130.16992.hdf5\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 15548.6025 - mean_absolute_error: 15548.6025 - val_loss: 15784.8740 - val_mean_absolute_error: 15784.8740\n",
      "\n",
      "Epoch 00035: val_loss improved from 16130.16992 to 15784.87402, saving model to Weights-035--15784.87402.hdf5\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 15181.0703 - mean_absolute_error: 15181.0703 - val_loss: 15460.2529 - val_mean_absolute_error: 15460.2529\n",
      "\n",
      "Epoch 00036: val_loss improved from 15784.87402 to 15460.25293, saving model to Weights-036--15460.25293.hdf5\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 14836.0469 - mean_absolute_error: 14836.0469 - val_loss: 15149.1123 - val_mean_absolute_error: 15149.1123\n",
      "\n",
      "Epoch 00037: val_loss improved from 15460.25293 to 15149.11230, saving model to Weights-037--15149.11230.hdf5\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 14506.9414 - mean_absolute_error: 14506.9414 - val_loss: 14863.7656 - val_mean_absolute_error: 14863.7656\n",
      "\n",
      "Epoch 00038: val_loss improved from 15149.11230 to 14863.76562, saving model to Weights-038--14863.76562.hdf5\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 14196.8809 - mean_absolute_error: 14196.8809 - val_loss: 14585.6562 - val_mean_absolute_error: 14585.6562\n",
      "\n",
      "Epoch 00039: val_loss improved from 14863.76562 to 14585.65625, saving model to Weights-039--14585.65625.hdf5\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 13900.6289 - mean_absolute_error: 13900.6289 - val_loss: 14321.1523 - val_mean_absolute_error: 14321.1523\n",
      "\n",
      "Epoch 00040: val_loss improved from 14585.65625 to 14321.15234, saving model to Weights-040--14321.15234.hdf5\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 13617.0879 - mean_absolute_error: 13617.0879 - val_loss: 14066.1748 - val_mean_absolute_error: 14066.1748\n",
      "\n",
      "Epoch 00041: val_loss improved from 14321.15234 to 14066.17480, saving model to Weights-041--14066.17480.hdf5\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 13340.2070 - mean_absolute_error: 13340.2070 - val_loss: 13827.4414 - val_mean_absolute_error: 13827.4414\n",
      "\n",
      "Epoch 00042: val_loss improved from 14066.17480 to 13827.44141, saving model to Weights-042--13827.44141.hdf5\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 13059.7314 - mean_absolute_error: 13059.7314 - val_loss: 13588.2441 - val_mean_absolute_error: 13588.2441\n",
      "\n",
      "Epoch 00043: val_loss improved from 13827.44141 to 13588.24414, saving model to Weights-043--13588.24414.hdf5\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 12791.3418 - mean_absolute_error: 12791.3418 - val_loss: 13368.3467 - val_mean_absolute_error: 13368.3467\n",
      "\n",
      "Epoch 00044: val_loss improved from 13588.24414 to 13368.34668, saving model to Weights-044--13368.34668.hdf5\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 12532.6172 - mean_absolute_error: 12532.6172 - val_loss: 13154.5264 - val_mean_absolute_error: 13154.5264\n",
      "\n",
      "Epoch 00045: val_loss improved from 13368.34668 to 13154.52637, saving model to Weights-045--13154.52637.hdf5\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 12288.4229 - mean_absolute_error: 12288.4229 - val_loss: 12951.6016 - val_mean_absolute_error: 12951.6016\n",
      "\n",
      "Epoch 00046: val_loss improved from 13154.52637 to 12951.60156, saving model to Weights-046--12951.60156.hdf5\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 12062.2969 - mean_absolute_error: 12062.2969 - val_loss: 12755.4121 - val_mean_absolute_error: 12755.4121\n",
      "\n",
      "Epoch 00047: val_loss improved from 12951.60156 to 12755.41211, saving model to Weights-047--12755.41211.hdf5\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11845.2305 - mean_absolute_error: 11845.2305 - val_loss: 12577.2070 - val_mean_absolute_error: 12577.2070\n",
      "\n",
      "Epoch 00048: val_loss improved from 12755.41211 to 12577.20703, saving model to Weights-048--12577.20703.hdf5\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11640.4434 - mean_absolute_error: 11640.4434 - val_loss: 12414.9736 - val_mean_absolute_error: 12414.9736\n",
      "\n",
      "Epoch 00049: val_loss improved from 12577.20703 to 12414.97363, saving model to Weights-049--12414.97363.hdf5\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11449.1406 - mean_absolute_error: 11449.1406 - val_loss: 12261.7676 - val_mean_absolute_error: 12261.7676\n",
      "\n",
      "Epoch 00050: val_loss improved from 12414.97363 to 12261.76758, saving model to Weights-050--12261.76758.hdf5\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11268.5859 - mean_absolute_error: 11268.5859 - val_loss: 12121.8730 - val_mean_absolute_error: 12121.8730\n",
      "\n",
      "Epoch 00051: val_loss improved from 12261.76758 to 12121.87305, saving model to Weights-051--12121.87305.hdf5\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11102.4795 - mean_absolute_error: 11102.4795 - val_loss: 11991.1963 - val_mean_absolute_error: 11991.1963\n",
      "\n",
      "Epoch 00052: val_loss improved from 12121.87305 to 11991.19629, saving model to Weights-052--11991.19629.hdf5\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 10945.7354 - mean_absolute_error: 10945.7354 - val_loss: 11872.7793 - val_mean_absolute_error: 11872.7793\n",
      "\n",
      "Epoch 00053: val_loss improved from 11991.19629 to 11872.77930, saving model to Weights-053--11872.77930.hdf5\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10796.7090 - mean_absolute_error: 10796.7090 - val_loss: 11760.3809 - val_mean_absolute_error: 11760.3809\n",
      "\n",
      "Epoch 00054: val_loss improved from 11872.77930 to 11760.38086, saving model to Weights-054--11760.38086.hdf5\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 10661.2578 - mean_absolute_error: 10661.2578 - val_loss: 11653.4004 - val_mean_absolute_error: 11653.4004\n",
      "\n",
      "Epoch 00055: val_loss improved from 11760.38086 to 11653.40039, saving model to Weights-055--11653.40039.hdf5\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 10533.4775 - mean_absolute_error: 10533.4775 - val_loss: 11560.2012 - val_mean_absolute_error: 11560.2012\n",
      "\n",
      "Epoch 00056: val_loss improved from 11653.40039 to 11560.20117, saving model to Weights-056--11560.20117.hdf5\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 10413.1396 - mean_absolute_error: 10413.1396 - val_loss: 11469.8691 - val_mean_absolute_error: 11469.8691\n",
      "\n",
      "Epoch 00057: val_loss improved from 11560.20117 to 11469.86914, saving model to Weights-057--11469.86914.hdf5\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 10301.9502 - mean_absolute_error: 10301.9502 - val_loss: 11387.7520 - val_mean_absolute_error: 11387.7520\n",
      "\n",
      "Epoch 00058: val_loss improved from 11469.86914 to 11387.75195, saving model to Weights-058--11387.75195.hdf5\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 10197.3662 - mean_absolute_error: 10197.3662 - val_loss: 11306.1357 - val_mean_absolute_error: 11306.1357\n",
      "\n",
      "Epoch 00059: val_loss improved from 11387.75195 to 11306.13574, saving model to Weights-059--11306.13574.hdf5\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10094.3789 - mean_absolute_error: 10094.3789 - val_loss: 11235.1182 - val_mean_absolute_error: 11235.1182\n",
      "\n",
      "Epoch 00060: val_loss improved from 11306.13574 to 11235.11816, saving model to Weights-060--11235.11816.hdf5\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 10000.2656 - mean_absolute_error: 10000.2656 - val_loss: 11166.9004 - val_mean_absolute_error: 11166.9004\n",
      "\n",
      "Epoch 00061: val_loss improved from 11235.11816 to 11166.90039, saving model to Weights-061--11166.90039.hdf5\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 9905.1064 - mean_absolute_error: 9905.1064 - val_loss: 11095.3525 - val_mean_absolute_error: 11095.3525\n",
      "\n",
      "Epoch 00062: val_loss improved from 11166.90039 to 11095.35254, saving model to Weights-062--11095.35254.hdf5\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9816.5547 - mean_absolute_error: 9816.5547 - val_loss: 11029.4951 - val_mean_absolute_error: 11029.4951\n",
      "\n",
      "Epoch 00063: val_loss improved from 11095.35254 to 11029.49512, saving model to Weights-063--11029.49512.hdf5\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9733.2207 - mean_absolute_error: 9733.2207 - val_loss: 10971.5088 - val_mean_absolute_error: 10971.5088\n",
      "\n",
      "Epoch 00064: val_loss improved from 11029.49512 to 10971.50879, saving model to Weights-064--10971.50879.hdf5\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 9656.9248 - mean_absolute_error: 9656.9248 - val_loss: 10923.0264 - val_mean_absolute_error: 10923.0264\n",
      "\n",
      "Epoch 00065: val_loss improved from 10971.50879 to 10923.02637, saving model to Weights-065--10923.02637.hdf5\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 9585.1445 - mean_absolute_error: 9585.1445 - val_loss: 10872.3711 - val_mean_absolute_error: 10872.3711\n",
      "\n",
      "Epoch 00066: val_loss improved from 10923.02637 to 10872.37109, saving model to Weights-066--10872.37109.hdf5\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 9516.1826 - mean_absolute_error: 9516.1826 - val_loss: 10822.3662 - val_mean_absolute_error: 10822.3662\n",
      "\n",
      "Epoch 00067: val_loss improved from 10872.37109 to 10822.36621, saving model to Weights-067--10822.36621.hdf5\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 9448.2715 - mean_absolute_error: 9448.2715 - val_loss: 10778.3574 - val_mean_absolute_error: 10778.3574\n",
      "\n",
      "Epoch 00068: val_loss improved from 10822.36621 to 10778.35742, saving model to Weights-068--10778.35742.hdf5\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9385.0635 - mean_absolute_error: 9385.0635 - val_loss: 10733.9033 - val_mean_absolute_error: 10733.9033\n",
      "\n",
      "Epoch 00069: val_loss improved from 10778.35742 to 10733.90332, saving model to Weights-069--10733.90332.hdf5\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9321.3877 - mean_absolute_error: 9321.3877 - val_loss: 10688.3525 - val_mean_absolute_error: 10688.3525\n",
      "\n",
      "Epoch 00070: val_loss improved from 10733.90332 to 10688.35254, saving model to Weights-070--10688.35254.hdf5\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9259.0605 - mean_absolute_error: 9259.0605 - val_loss: 10648.9756 - val_mean_absolute_error: 10648.9756\n",
      "\n",
      "Epoch 00071: val_loss improved from 10688.35254 to 10648.97559, saving model to Weights-071--10648.97559.hdf5\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9198.6406 - mean_absolute_error: 9198.6406 - val_loss: 10608.9199 - val_mean_absolute_error: 10608.9199\n",
      "\n",
      "Epoch 00072: val_loss improved from 10648.97559 to 10608.91992, saving model to Weights-072--10608.91992.hdf5\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9140.5498 - mean_absolute_error: 9140.5498 - val_loss: 10573.5137 - val_mean_absolute_error: 10573.5137\n",
      "\n",
      "Epoch 00073: val_loss improved from 10608.91992 to 10573.51367, saving model to Weights-073--10573.51367.hdf5\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 9085.6973 - mean_absolute_error: 9085.6973 - val_loss: 10542.9736 - val_mean_absolute_error: 10542.9736\n",
      "\n",
      "Epoch 00074: val_loss improved from 10573.51367 to 10542.97363, saving model to Weights-074--10542.97363.hdf5\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 9031.6357 - mean_absolute_error: 9031.6357 - val_loss: 10512.7109 - val_mean_absolute_error: 10512.7109\n",
      "\n",
      "Epoch 00075: val_loss improved from 10542.97363 to 10512.71094, saving model to Weights-075--10512.71094.hdf5\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8981.1553 - mean_absolute_error: 8981.1553 - val_loss: 10483.4951 - val_mean_absolute_error: 10483.4951\n",
      "\n",
      "Epoch 00076: val_loss improved from 10512.71094 to 10483.49512, saving model to Weights-076--10483.49512.hdf5\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8932.9375 - mean_absolute_error: 8932.9375 - val_loss: 10460.6084 - val_mean_absolute_error: 10460.6084\n",
      "\n",
      "Epoch 00077: val_loss improved from 10483.49512 to 10460.60840, saving model to Weights-077--10460.60840.hdf5\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8885.2490 - mean_absolute_error: 8885.2490 - val_loss: 10434.7686 - val_mean_absolute_error: 10434.7686\n",
      "\n",
      "Epoch 00078: val_loss improved from 10460.60840 to 10434.76855, saving model to Weights-078--10434.76855.hdf5\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8839.8047 - mean_absolute_error: 8839.8047 - val_loss: 10410.2158 - val_mean_absolute_error: 10410.2158\n",
      "\n",
      "Epoch 00079: val_loss improved from 10434.76855 to 10410.21582, saving model to Weights-079--10410.21582.hdf5\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8795.0264 - mean_absolute_error: 8795.0264 - val_loss: 10385.1709 - val_mean_absolute_error: 10385.1709\n",
      "\n",
      "Epoch 00080: val_loss improved from 10410.21582 to 10385.17090, saving model to Weights-080--10385.17090.hdf5\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8749.9668 - mean_absolute_error: 8749.9668 - val_loss: 10361.1035 - val_mean_absolute_error: 10361.1035\n",
      "\n",
      "Epoch 00081: val_loss improved from 10385.17090 to 10361.10352, saving model to Weights-081--10361.10352.hdf5\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8705.7500 - mean_absolute_error: 8705.7500 - val_loss: 10333.8623 - val_mean_absolute_error: 10333.8623\n",
      "\n",
      "Epoch 00082: val_loss improved from 10361.10352 to 10333.86230, saving model to Weights-082--10333.86230.hdf5\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8662.4912 - mean_absolute_error: 8662.4912 - val_loss: 10311.0010 - val_mean_absolute_error: 10311.0010\n",
      "\n",
      "Epoch 00083: val_loss improved from 10333.86230 to 10311.00098, saving model to Weights-083--10311.00098.hdf5\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8620.0146 - mean_absolute_error: 8620.0146 - val_loss: 10291.2334 - val_mean_absolute_error: 10291.2334\n",
      "\n",
      "Epoch 00084: val_loss improved from 10311.00098 to 10291.23340, saving model to Weights-084--10291.23340.hdf5\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8580.0723 - mean_absolute_error: 8580.0723 - val_loss: 10270.5508 - val_mean_absolute_error: 10270.5508\n",
      "\n",
      "Epoch 00085: val_loss improved from 10291.23340 to 10270.55078, saving model to Weights-085--10270.55078.hdf5\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8540.0537 - mean_absolute_error: 8540.0537 - val_loss: 10247.4834 - val_mean_absolute_error: 10247.4834\n",
      "\n",
      "Epoch 00086: val_loss improved from 10270.55078 to 10247.48340, saving model to Weights-086--10247.48340.hdf5\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8502.3701 - mean_absolute_error: 8502.3701 - val_loss: 10228.0322 - val_mean_absolute_error: 10228.0322\n",
      "\n",
      "Epoch 00087: val_loss improved from 10247.48340 to 10228.03223, saving model to Weights-087--10228.03223.hdf5\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8466.1162 - mean_absolute_error: 8466.1162 - val_loss: 10208.6338 - val_mean_absolute_error: 10208.6338\n",
      "\n",
      "Epoch 00088: val_loss improved from 10228.03223 to 10208.63379, saving model to Weights-088--10208.63379.hdf5\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8430.9912 - mean_absolute_error: 8430.9912 - val_loss: 10192.2832 - val_mean_absolute_error: 10192.2832\n",
      "\n",
      "Epoch 00089: val_loss improved from 10208.63379 to 10192.28320, saving model to Weights-089--10192.28320.hdf5\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8396.9336 - mean_absolute_error: 8396.9336 - val_loss: 10170.8848 - val_mean_absolute_error: 10170.8848\n",
      "\n",
      "Epoch 00090: val_loss improved from 10192.28320 to 10170.88477, saving model to Weights-090--10170.88477.hdf5\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8363.1572 - mean_absolute_error: 8363.1572 - val_loss: 10152.5996 - val_mean_absolute_error: 10152.5996\n",
      "\n",
      "Epoch 00091: val_loss improved from 10170.88477 to 10152.59961, saving model to Weights-091--10152.59961.hdf5\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8330.9736 - mean_absolute_error: 8330.9736 - val_loss: 10138.7393 - val_mean_absolute_error: 10138.7393\n",
      "\n",
      "Epoch 00092: val_loss improved from 10152.59961 to 10138.73926, saving model to Weights-092--10138.73926.hdf5\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8299.2666 - mean_absolute_error: 8299.2666 - val_loss: 10122.8906 - val_mean_absolute_error: 10122.8906\n",
      "\n",
      "Epoch 00093: val_loss improved from 10138.73926 to 10122.89062, saving model to Weights-093--10122.89062.hdf5\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8267.2607 - mean_absolute_error: 8267.2607 - val_loss: 10104.6494 - val_mean_absolute_error: 10104.6494\n",
      "\n",
      "Epoch 00094: val_loss improved from 10122.89062 to 10104.64941, saving model to Weights-094--10104.64941.hdf5\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8236.3809 - mean_absolute_error: 8236.3809 - val_loss: 10087.0039 - val_mean_absolute_error: 10087.0039\n",
      "\n",
      "Epoch 00095: val_loss improved from 10104.64941 to 10087.00391, saving model to Weights-095--10087.00391.hdf5\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8205.8096 - mean_absolute_error: 8205.8096 - val_loss: 10069.0654 - val_mean_absolute_error: 10069.0654\n",
      "\n",
      "Epoch 00096: val_loss improved from 10087.00391 to 10069.06543, saving model to Weights-096--10069.06543.hdf5\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8175.8335 - mean_absolute_error: 8175.8335 - val_loss: 10055.9893 - val_mean_absolute_error: 10055.9893\n",
      "\n",
      "Epoch 00097: val_loss improved from 10069.06543 to 10055.98926, saving model to Weights-097--10055.98926.hdf5\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8145.5190 - mean_absolute_error: 8145.5190 - val_loss: 10037.3818 - val_mean_absolute_error: 10037.3818\n",
      "\n",
      "Epoch 00098: val_loss improved from 10055.98926 to 10037.38184, saving model to Weights-098--10037.38184.hdf5\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8117.2871 - mean_absolute_error: 8117.2871 - val_loss: 10023.4375 - val_mean_absolute_error: 10023.4375\n",
      "\n",
      "Epoch 00099: val_loss improved from 10037.38184 to 10023.43750, saving model to Weights-099--10023.43750.hdf5\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 8086.5205 - mean_absolute_error: 8086.5205 - val_loss: 10009.6641 - val_mean_absolute_error: 10009.6641\n",
      "\n",
      "Epoch 00100: val_loss improved from 10023.43750 to 10009.66406, saving model to Weights-100--10009.66406.hdf5\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8059.8740 - mean_absolute_error: 8059.8740 - val_loss: 9998.0791 - val_mean_absolute_error: 9998.0791\n",
      "\n",
      "Epoch 00101: val_loss improved from 10009.66406 to 9998.07910, saving model to Weights-101--9998.07910.hdf5\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8031.2681 - mean_absolute_error: 8031.2681 - val_loss: 9979.6299 - val_mean_absolute_error: 9979.6299\n",
      "\n",
      "Epoch 00102: val_loss improved from 9998.07910 to 9979.62988, saving model to Weights-102--9979.62988.hdf5\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 8001.4512 - mean_absolute_error: 8001.4512 - val_loss: 9968.2676 - val_mean_absolute_error: 9968.2676\n",
      "\n",
      "Epoch 00103: val_loss improved from 9979.62988 to 9968.26758, saving model to Weights-103--9968.26758.hdf5\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7974.3779 - mean_absolute_error: 7974.3779 - val_loss: 9952.8350 - val_mean_absolute_error: 9952.8350\n",
      "\n",
      "Epoch 00104: val_loss improved from 9968.26758 to 9952.83496, saving model to Weights-104--9952.83496.hdf5\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7946.1133 - mean_absolute_error: 7946.1133 - val_loss: 9942.5303 - val_mean_absolute_error: 9942.5303\n",
      "\n",
      "Epoch 00105: val_loss improved from 9952.83496 to 9942.53027, saving model to Weights-105--9942.53027.hdf5\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7919.1094 - mean_absolute_error: 7919.1094 - val_loss: 9928.8477 - val_mean_absolute_error: 9928.8477\n",
      "\n",
      "Epoch 00106: val_loss improved from 9942.53027 to 9928.84766, saving model to Weights-106--9928.84766.hdf5\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7893.9702 - mean_absolute_error: 7893.9702 - val_loss: 9915.3369 - val_mean_absolute_error: 9915.3369\n",
      "\n",
      "Epoch 00107: val_loss improved from 9928.84766 to 9915.33691, saving model to Weights-107--9915.33691.hdf5\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7868.2471 - mean_absolute_error: 7868.2471 - val_loss: 9904.3340 - val_mean_absolute_error: 9904.3340\n",
      "\n",
      "Epoch 00108: val_loss improved from 9915.33691 to 9904.33398, saving model to Weights-108--9904.33398.hdf5\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7841.7803 - mean_absolute_error: 7841.7803 - val_loss: 9892.5410 - val_mean_absolute_error: 9892.5410\n",
      "\n",
      "Epoch 00109: val_loss improved from 9904.33398 to 9892.54102, saving model to Weights-109--9892.54102.hdf5\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7816.2559 - mean_absolute_error: 7816.2559 - val_loss: 9880.7471 - val_mean_absolute_error: 9880.7471\n",
      "\n",
      "Epoch 00110: val_loss improved from 9892.54102 to 9880.74707, saving model to Weights-110--9880.74707.hdf5\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7792.4648 - mean_absolute_error: 7792.4648 - val_loss: 9872.3428 - val_mean_absolute_error: 9872.3428\n",
      "\n",
      "Epoch 00111: val_loss improved from 9880.74707 to 9872.34277, saving model to Weights-111--9872.34277.hdf5\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7767.4849 - mean_absolute_error: 7767.4849 - val_loss: 9862.0820 - val_mean_absolute_error: 9862.0820\n",
      "\n",
      "Epoch 00112: val_loss improved from 9872.34277 to 9862.08203, saving model to Weights-112--9862.08203.hdf5\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7744.2539 - mean_absolute_error: 7744.2539 - val_loss: 9849.7686 - val_mean_absolute_error: 9849.7686\n",
      "\n",
      "Epoch 00113: val_loss improved from 9862.08203 to 9849.76855, saving model to Weights-113--9849.76855.hdf5\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7718.9097 - mean_absolute_error: 7718.9097 - val_loss: 9842.1699 - val_mean_absolute_error: 9842.1699\n",
      "\n",
      "Epoch 00114: val_loss improved from 9849.76855 to 9842.16992, saving model to Weights-114--9842.16992.hdf5\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7696.2642 - mean_absolute_error: 7696.2642 - val_loss: 9834.2959 - val_mean_absolute_error: 9834.2959\n",
      "\n",
      "Epoch 00115: val_loss improved from 9842.16992 to 9834.29590, saving model to Weights-115--9834.29590.hdf5\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7672.4263 - mean_absolute_error: 7672.4263 - val_loss: 9822.5078 - val_mean_absolute_error: 9822.5078\n",
      "\n",
      "Epoch 00116: val_loss improved from 9834.29590 to 9822.50781, saving model to Weights-116--9822.50781.hdf5\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7648.7515 - mean_absolute_error: 7648.7515 - val_loss: 9815.4619 - val_mean_absolute_error: 9815.4619\n",
      "\n",
      "Epoch 00117: val_loss improved from 9822.50781 to 9815.46191, saving model to Weights-117--9815.46191.hdf5\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7625.8540 - mean_absolute_error: 7625.8540 - val_loss: 9803.9004 - val_mean_absolute_error: 9803.9004\n",
      "\n",
      "Epoch 00118: val_loss improved from 9815.46191 to 9803.90039, saving model to Weights-118--9803.90039.hdf5\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7602.6626 - mean_absolute_error: 7602.6626 - val_loss: 9796.2539 - val_mean_absolute_error: 9796.2539\n",
      "\n",
      "Epoch 00119: val_loss improved from 9803.90039 to 9796.25391, saving model to Weights-119--9796.25391.hdf5\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7582.0625 - mean_absolute_error: 7582.0625 - val_loss: 9788.5967 - val_mean_absolute_error: 9788.5967\n",
      "\n",
      "Epoch 00120: val_loss improved from 9796.25391 to 9788.59668, saving model to Weights-120--9788.59668.hdf5\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7561.0806 - mean_absolute_error: 7561.0806 - val_loss: 9779.1426 - val_mean_absolute_error: 9779.1426\n",
      "\n",
      "Epoch 00121: val_loss improved from 9788.59668 to 9779.14258, saving model to Weights-121--9779.14258.hdf5\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7537.8252 - mean_absolute_error: 7537.8252 - val_loss: 9770.7402 - val_mean_absolute_error: 9770.7402\n",
      "\n",
      "Epoch 00122: val_loss improved from 9779.14258 to 9770.74023, saving model to Weights-122--9770.74023.hdf5\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7516.3037 - mean_absolute_error: 7516.3037 - val_loss: 9762.8340 - val_mean_absolute_error: 9762.8340\n",
      "\n",
      "Epoch 00123: val_loss improved from 9770.74023 to 9762.83398, saving model to Weights-123--9762.83398.hdf5\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7494.3652 - mean_absolute_error: 7494.3652 - val_loss: 9754.9521 - val_mean_absolute_error: 9754.9521\n",
      "\n",
      "Epoch 00124: val_loss improved from 9762.83398 to 9754.95215, saving model to Weights-124--9754.95215.hdf5\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7473.1230 - mean_absolute_error: 7473.1230 - val_loss: 9744.4824 - val_mean_absolute_error: 9744.4824\n",
      "\n",
      "Epoch 00125: val_loss improved from 9754.95215 to 9744.48242, saving model to Weights-125--9744.48242.hdf5\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7451.8394 - mean_absolute_error: 7451.8394 - val_loss: 9738.9062 - val_mean_absolute_error: 9738.9062\n",
      "\n",
      "Epoch 00126: val_loss improved from 9744.48242 to 9738.90625, saving model to Weights-126--9738.90625.hdf5\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7431.7422 - mean_absolute_error: 7431.7422 - val_loss: 9728.9688 - val_mean_absolute_error: 9728.9688\n",
      "\n",
      "Epoch 00127: val_loss improved from 9738.90625 to 9728.96875, saving model to Weights-127--9728.96875.hdf5\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7410.5635 - mean_absolute_error: 7410.5635 - val_loss: 9722.0371 - val_mean_absolute_error: 9722.0371\n",
      "\n",
      "Epoch 00128: val_loss improved from 9728.96875 to 9722.03711, saving model to Weights-128--9722.03711.hdf5\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7391.4219 - mean_absolute_error: 7391.4219 - val_loss: 9714.4307 - val_mean_absolute_error: 9714.4307\n",
      "\n",
      "Epoch 00129: val_loss improved from 9722.03711 to 9714.43066, saving model to Weights-129--9714.43066.hdf5\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7371.5415 - mean_absolute_error: 7371.5415 - val_loss: 9701.0205 - val_mean_absolute_error: 9701.0205\n",
      "\n",
      "Epoch 00130: val_loss improved from 9714.43066 to 9701.02051, saving model to Weights-130--9701.02051.hdf5\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7351.8838 - mean_absolute_error: 7351.8838 - val_loss: 9695.5410 - val_mean_absolute_error: 9695.5410\n",
      "\n",
      "Epoch 00131: val_loss improved from 9701.02051 to 9695.54102, saving model to Weights-131--9695.54102.hdf5\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7332.1577 - mean_absolute_error: 7332.1577 - val_loss: 9687.7588 - val_mean_absolute_error: 9687.7588\n",
      "\n",
      "Epoch 00132: val_loss improved from 9695.54102 to 9687.75879, saving model to Weights-132--9687.75879.hdf5\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7312.7178 - mean_absolute_error: 7312.7178 - val_loss: 9681.0859 - val_mean_absolute_error: 9681.0859\n",
      "\n",
      "Epoch 00133: val_loss improved from 9687.75879 to 9681.08594, saving model to Weights-133--9681.08594.hdf5\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7292.6821 - mean_absolute_error: 7292.6821 - val_loss: 9674.3545 - val_mean_absolute_error: 9674.3545\n",
      "\n",
      "Epoch 00134: val_loss improved from 9681.08594 to 9674.35449, saving model to Weights-134--9674.35449.hdf5\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7274.5698 - mean_absolute_error: 7274.5698 - val_loss: 9667.3857 - val_mean_absolute_error: 9667.3857\n",
      "\n",
      "Epoch 00135: val_loss improved from 9674.35449 to 9667.38574, saving model to Weights-135--9667.38574.hdf5\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7255.3643 - mean_absolute_error: 7255.3643 - val_loss: 9660.5840 - val_mean_absolute_error: 9660.5840\n",
      "\n",
      "Epoch 00136: val_loss improved from 9667.38574 to 9660.58398, saving model to Weights-136--9660.58398.hdf5\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7237.6157 - mean_absolute_error: 7237.6157 - val_loss: 9654.6143 - val_mean_absolute_error: 9654.6143\n",
      "\n",
      "Epoch 00137: val_loss improved from 9660.58398 to 9654.61426, saving model to Weights-137--9654.61426.hdf5\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7217.2051 - mean_absolute_error: 7217.2051 - val_loss: 9646.6123 - val_mean_absolute_error: 9646.6123\n",
      "\n",
      "Epoch 00138: val_loss improved from 9654.61426 to 9646.61230, saving model to Weights-138--9646.61230.hdf5\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7199.4702 - mean_absolute_error: 7199.4702 - val_loss: 9643.1875 - val_mean_absolute_error: 9643.1875\n",
      "\n",
      "Epoch 00139: val_loss improved from 9646.61230 to 9643.18750, saving model to Weights-139--9643.18750.hdf5\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7181.2617 - mean_absolute_error: 7181.2617 - val_loss: 9634.7969 - val_mean_absolute_error: 9634.7969\n",
      "\n",
      "Epoch 00140: val_loss improved from 9643.18750 to 9634.79688, saving model to Weights-140--9634.79688.hdf5\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7162.4346 - mean_absolute_error: 7162.4346 - val_loss: 9629.3525 - val_mean_absolute_error: 9629.3525\n",
      "\n",
      "Epoch 00141: val_loss improved from 9634.79688 to 9629.35254, saving model to Weights-141--9629.35254.hdf5\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7144.2847 - mean_absolute_error: 7144.2847 - val_loss: 9620.1055 - val_mean_absolute_error: 9620.1055\n",
      "\n",
      "Epoch 00142: val_loss improved from 9629.35254 to 9620.10547, saving model to Weights-142--9620.10547.hdf5\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7126.8340 - mean_absolute_error: 7126.8340 - val_loss: 9616.3359 - val_mean_absolute_error: 9616.3359\n",
      "\n",
      "Epoch 00143: val_loss improved from 9620.10547 to 9616.33594, saving model to Weights-143--9616.33594.hdf5\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7109.0078 - mean_absolute_error: 7109.0078 - val_loss: 9609.6543 - val_mean_absolute_error: 9609.6543\n",
      "\n",
      "Epoch 00144: val_loss improved from 9616.33594 to 9609.65430, saving model to Weights-144--9609.65430.hdf5\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7092.5952 - mean_absolute_error: 7092.5952 - val_loss: 9604.6514 - val_mean_absolute_error: 9604.6514\n",
      "\n",
      "Epoch 00145: val_loss improved from 9609.65430 to 9604.65137, saving model to Weights-145--9604.65137.hdf5\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7075.7861 - mean_absolute_error: 7075.7861 - val_loss: 9598.9951 - val_mean_absolute_error: 9598.9951\n",
      "\n",
      "Epoch 00146: val_loss improved from 9604.65137 to 9598.99512, saving model to Weights-146--9598.99512.hdf5\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7058.3887 - mean_absolute_error: 7058.3887 - val_loss: 9591.3584 - val_mean_absolute_error: 9591.3584\n",
      "\n",
      "Epoch 00147: val_loss improved from 9598.99512 to 9591.35840, saving model to Weights-147--9591.35840.hdf5\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7041.3613 - mean_absolute_error: 7041.3613 - val_loss: 9589.4375 - val_mean_absolute_error: 9589.4375\n",
      "\n",
      "Epoch 00148: val_loss improved from 9591.35840 to 9589.43750, saving model to Weights-148--9589.43750.hdf5\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7025.5674 - mean_absolute_error: 7025.5674 - val_loss: 9582.0283 - val_mean_absolute_error: 9582.0283\n",
      "\n",
      "Epoch 00149: val_loss improved from 9589.43750 to 9582.02832, saving model to Weights-149--9582.02832.hdf5\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 7008.5469 - mean_absolute_error: 7008.5469 - val_loss: 9576.0293 - val_mean_absolute_error: 9576.0293\n",
      "\n",
      "Epoch 00150: val_loss improved from 9582.02832 to 9576.02930, saving model to Weights-150--9576.02930.hdf5\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6991.7993 - mean_absolute_error: 6991.7993 - val_loss: 9571.0879 - val_mean_absolute_error: 9571.0879\n",
      "\n",
      "Epoch 00151: val_loss improved from 9576.02930 to 9571.08789, saving model to Weights-151--9571.08789.hdf5\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6975.2422 - mean_absolute_error: 6975.2422 - val_loss: 9565.5244 - val_mean_absolute_error: 9565.5244\n",
      "\n",
      "Epoch 00152: val_loss improved from 9571.08789 to 9565.52441, saving model to Weights-152--9565.52441.hdf5\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6960.3232 - mean_absolute_error: 6960.3232 - val_loss: 9560.4404 - val_mean_absolute_error: 9560.4404\n",
      "\n",
      "Epoch 00153: val_loss improved from 9565.52441 to 9560.44043, saving model to Weights-153--9560.44043.hdf5\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6943.5444 - mean_absolute_error: 6943.5444 - val_loss: 9556.1240 - val_mean_absolute_error: 9556.1240\n",
      "\n",
      "Epoch 00154: val_loss improved from 9560.44043 to 9556.12402, saving model to Weights-154--9556.12402.hdf5\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6926.8882 - mean_absolute_error: 6926.8882 - val_loss: 9550.6045 - val_mean_absolute_error: 9550.6045\n",
      "\n",
      "Epoch 00155: val_loss improved from 9556.12402 to 9550.60449, saving model to Weights-155--9550.60449.hdf5\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6912.5908 - mean_absolute_error: 6912.5908 - val_loss: 9543.7305 - val_mean_absolute_error: 9543.7305\n",
      "\n",
      "Epoch 00156: val_loss improved from 9550.60449 to 9543.73047, saving model to Weights-156--9543.73047.hdf5\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6894.8647 - mean_absolute_error: 6894.8647 - val_loss: 9540.6055 - val_mean_absolute_error: 9540.6055\n",
      "\n",
      "Epoch 00157: val_loss improved from 9543.73047 to 9540.60547, saving model to Weights-157--9540.60547.hdf5\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6880.7715 - mean_absolute_error: 6880.7715 - val_loss: 9536.9424 - val_mean_absolute_error: 9536.9424\n",
      "\n",
      "Epoch 00158: val_loss improved from 9540.60547 to 9536.94238, saving model to Weights-158--9536.94238.hdf5\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6863.9912 - mean_absolute_error: 6863.9912 - val_loss: 9532.3926 - val_mean_absolute_error: 9532.3926\n",
      "\n",
      "Epoch 00159: val_loss improved from 9536.94238 to 9532.39258, saving model to Weights-159--9532.39258.hdf5\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6848.7383 - mean_absolute_error: 6848.7383 - val_loss: 9527.2998 - val_mean_absolute_error: 9527.2998\n",
      "\n",
      "Epoch 00160: val_loss improved from 9532.39258 to 9527.29980, saving model to Weights-160--9527.29980.hdf5\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6833.3916 - mean_absolute_error: 6833.3916 - val_loss: 9524.4346 - val_mean_absolute_error: 9524.4346\n",
      "\n",
      "Epoch 00161: val_loss improved from 9527.29980 to 9524.43457, saving model to Weights-161--9524.43457.hdf5\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6817.0132 - mean_absolute_error: 6817.0132 - val_loss: 9519.3877 - val_mean_absolute_error: 9519.3877\n",
      "\n",
      "Epoch 00162: val_loss improved from 9524.43457 to 9519.38770, saving model to Weights-162--9519.38770.hdf5\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6801.1523 - mean_absolute_error: 6801.1523 - val_loss: 9512.8584 - val_mean_absolute_error: 9512.8584\n",
      "\n",
      "Epoch 00163: val_loss improved from 9519.38770 to 9512.85840, saving model to Weights-163--9512.85840.hdf5\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6787.3306 - mean_absolute_error: 6787.3306 - val_loss: 9508.9932 - val_mean_absolute_error: 9508.9932\n",
      "\n",
      "Epoch 00164: val_loss improved from 9512.85840 to 9508.99316, saving model to Weights-164--9508.99316.hdf5\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6772.4473 - mean_absolute_error: 6772.4473 - val_loss: 9504.1377 - val_mean_absolute_error: 9504.1377\n",
      "\n",
      "Epoch 00165: val_loss improved from 9508.99316 to 9504.13770, saving model to Weights-165--9504.13770.hdf5\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6759.3730 - mean_absolute_error: 6759.3730 - val_loss: 9501.6943 - val_mean_absolute_error: 9501.6943\n",
      "\n",
      "Epoch 00166: val_loss improved from 9504.13770 to 9501.69434, saving model to Weights-166--9501.69434.hdf5\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6743.4385 - mean_absolute_error: 6743.4385 - val_loss: 9495.1240 - val_mean_absolute_error: 9495.1240\n",
      "\n",
      "Epoch 00167: val_loss improved from 9501.69434 to 9495.12402, saving model to Weights-167--9495.12402.hdf5\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6729.3589 - mean_absolute_error: 6729.3589 - val_loss: 9491.0781 - val_mean_absolute_error: 9491.0781\n",
      "\n",
      "Epoch 00168: val_loss improved from 9495.12402 to 9491.07812, saving model to Weights-168--9491.07812.hdf5\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6715.8369 - mean_absolute_error: 6715.8369 - val_loss: 9485.4941 - val_mean_absolute_error: 9485.4941\n",
      "\n",
      "Epoch 00169: val_loss improved from 9491.07812 to 9485.49414, saving model to Weights-169--9485.49414.hdf5\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6701.0864 - mean_absolute_error: 6701.0864 - val_loss: 9483.7900 - val_mean_absolute_error: 9483.7900\n",
      "\n",
      "Epoch 00170: val_loss improved from 9485.49414 to 9483.79004, saving model to Weights-170--9483.79004.hdf5\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6687.8125 - mean_absolute_error: 6687.8125 - val_loss: 9479.9297 - val_mean_absolute_error: 9479.9297\n",
      "\n",
      "Epoch 00171: val_loss improved from 9483.79004 to 9479.92969, saving model to Weights-171--9479.92969.hdf5\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6673.3501 - mean_absolute_error: 6673.3501 - val_loss: 9476.5664 - val_mean_absolute_error: 9476.5664\n",
      "\n",
      "Epoch 00172: val_loss improved from 9479.92969 to 9476.56641, saving model to Weights-172--9476.56641.hdf5\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6659.0869 - mean_absolute_error: 6659.0869 - val_loss: 9472.8730 - val_mean_absolute_error: 9472.8730\n",
      "\n",
      "Epoch 00173: val_loss improved from 9476.56641 to 9472.87305, saving model to Weights-173--9472.87305.hdf5\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6646.0034 - mean_absolute_error: 6646.0034 - val_loss: 9468.7539 - val_mean_absolute_error: 9468.7539\n",
      "\n",
      "Epoch 00174: val_loss improved from 9472.87305 to 9468.75391, saving model to Weights-174--9468.75391.hdf5\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6631.6162 - mean_absolute_error: 6631.6162 - val_loss: 9464.0938 - val_mean_absolute_error: 9464.0938\n",
      "\n",
      "Epoch 00175: val_loss improved from 9468.75391 to 9464.09375, saving model to Weights-175--9464.09375.hdf5\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6618.2959 - mean_absolute_error: 6618.2959 - val_loss: 9460.0234 - val_mean_absolute_error: 9460.0234\n",
      "\n",
      "Epoch 00176: val_loss improved from 9464.09375 to 9460.02344, saving model to Weights-176--9460.02344.hdf5\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6604.9814 - mean_absolute_error: 6604.9814 - val_loss: 9455.1602 - val_mean_absolute_error: 9455.1602\n",
      "\n",
      "Epoch 00177: val_loss improved from 9460.02344 to 9455.16016, saving model to Weights-177--9455.16016.hdf5\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6592.4014 - mean_absolute_error: 6592.4014 - val_loss: 9451.2158 - val_mean_absolute_error: 9451.2158\n",
      "\n",
      "Epoch 00178: val_loss improved from 9455.16016 to 9451.21582, saving model to Weights-178--9451.21582.hdf5\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6578.2178 - mean_absolute_error: 6578.2178 - val_loss: 9448.3115 - val_mean_absolute_error: 9448.3115\n",
      "\n",
      "Epoch 00179: val_loss improved from 9451.21582 to 9448.31152, saving model to Weights-179--9448.31152.hdf5\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6564.8179 - mean_absolute_error: 6564.8179 - val_loss: 9443.1182 - val_mean_absolute_error: 9443.1182\n",
      "\n",
      "Epoch 00180: val_loss improved from 9448.31152 to 9443.11816, saving model to Weights-180--9443.11816.hdf5\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6551.9028 - mean_absolute_error: 6551.9028 - val_loss: 9439.2480 - val_mean_absolute_error: 9439.2480\n",
      "\n",
      "Epoch 00181: val_loss improved from 9443.11816 to 9439.24805, saving model to Weights-181--9439.24805.hdf5\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6538.0698 - mean_absolute_error: 6538.0698 - val_loss: 9434.4590 - val_mean_absolute_error: 9434.4590\n",
      "\n",
      "Epoch 00182: val_loss improved from 9439.24805 to 9434.45898, saving model to Weights-182--9434.45898.hdf5\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6526.4072 - mean_absolute_error: 6526.4072 - val_loss: 9428.1240 - val_mean_absolute_error: 9428.1240\n",
      "\n",
      "Epoch 00183: val_loss improved from 9434.45898 to 9428.12402, saving model to Weights-183--9428.12402.hdf5\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6511.7441 - mean_absolute_error: 6511.7441 - val_loss: 9426.2871 - val_mean_absolute_error: 9426.2871\n",
      "\n",
      "Epoch 00184: val_loss improved from 9428.12402 to 9426.28711, saving model to Weights-184--9426.28711.hdf5\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6500.6240 - mean_absolute_error: 6500.6240 - val_loss: 9423.1318 - val_mean_absolute_error: 9423.1318\n",
      "\n",
      "Epoch 00185: val_loss improved from 9426.28711 to 9423.13184, saving model to Weights-185--9423.13184.hdf5\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6486.3013 - mean_absolute_error: 6486.3013 - val_loss: 9417.2842 - val_mean_absolute_error: 9417.2842\n",
      "\n",
      "Epoch 00186: val_loss improved from 9423.13184 to 9417.28418, saving model to Weights-186--9417.28418.hdf5\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6474.4634 - mean_absolute_error: 6474.4634 - val_loss: 9416.3799 - val_mean_absolute_error: 9416.3799\n",
      "\n",
      "Epoch 00187: val_loss improved from 9417.28418 to 9416.37988, saving model to Weights-187--9416.37988.hdf5\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6462.3413 - mean_absolute_error: 6462.3413 - val_loss: 9412.3174 - val_mean_absolute_error: 9412.3174\n",
      "\n",
      "Epoch 00188: val_loss improved from 9416.37988 to 9412.31738, saving model to Weights-188--9412.31738.hdf5\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6448.1729 - mean_absolute_error: 6448.1729 - val_loss: 9410.8604 - val_mean_absolute_error: 9410.8604\n",
      "\n",
      "Epoch 00189: val_loss improved from 9412.31738 to 9410.86035, saving model to Weights-189--9410.86035.hdf5\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6436.8525 - mean_absolute_error: 6436.8525 - val_loss: 9407.6123 - val_mean_absolute_error: 9407.6123\n",
      "\n",
      "Epoch 00190: val_loss improved from 9410.86035 to 9407.61230, saving model to Weights-190--9407.61230.hdf5\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6425.2681 - mean_absolute_error: 6425.2681 - val_loss: 9402.0625 - val_mean_absolute_error: 9402.0625\n",
      "\n",
      "Epoch 00191: val_loss improved from 9407.61230 to 9402.06250, saving model to Weights-191--9402.06250.hdf5\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6412.2808 - mean_absolute_error: 6412.2808 - val_loss: 9396.8359 - val_mean_absolute_error: 9396.8359\n",
      "\n",
      "Epoch 00192: val_loss improved from 9402.06250 to 9396.83594, saving model to Weights-192--9396.83594.hdf5\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6400.0005 - mean_absolute_error: 6400.0005 - val_loss: 9393.0303 - val_mean_absolute_error: 9393.0303\n",
      "\n",
      "Epoch 00193: val_loss improved from 9396.83594 to 9393.03027, saving model to Weights-193--9393.03027.hdf5\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6387.5322 - mean_absolute_error: 6387.5322 - val_loss: 9391.0859 - val_mean_absolute_error: 9391.0859\n",
      "\n",
      "Epoch 00194: val_loss improved from 9393.03027 to 9391.08594, saving model to Weights-194--9391.08594.hdf5\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6376.3389 - mean_absolute_error: 6376.3389 - val_loss: 9383.4238 - val_mean_absolute_error: 9383.4238\n",
      "\n",
      "Epoch 00195: val_loss improved from 9391.08594 to 9383.42383, saving model to Weights-195--9383.42383.hdf5\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6362.7539 - mean_absolute_error: 6362.7539 - val_loss: 9380.9170 - val_mean_absolute_error: 9380.9170\n",
      "\n",
      "Epoch 00196: val_loss improved from 9383.42383 to 9380.91699, saving model to Weights-196--9380.91699.hdf5\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6351.2139 - mean_absolute_error: 6351.2139 - val_loss: 9378.8584 - val_mean_absolute_error: 9378.8584\n",
      "\n",
      "Epoch 00197: val_loss improved from 9380.91699 to 9378.85840, saving model to Weights-197--9378.85840.hdf5\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6339.3032 - mean_absolute_error: 6339.3032 - val_loss: 9373.9551 - val_mean_absolute_error: 9373.9551\n",
      "\n",
      "Epoch 00198: val_loss improved from 9378.85840 to 9373.95508, saving model to Weights-198--9373.95508.hdf5\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6326.7212 - mean_absolute_error: 6326.7212 - val_loss: 9370.6748 - val_mean_absolute_error: 9370.6748\n",
      "\n",
      "Epoch 00199: val_loss improved from 9373.95508 to 9370.67480, saving model to Weights-199--9370.67480.hdf5\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6314.8647 - mean_absolute_error: 6314.8647 - val_loss: 9367.6064 - val_mean_absolute_error: 9367.6064\n",
      "\n",
      "Epoch 00200: val_loss improved from 9370.67480 to 9367.60645, saving model to Weights-200--9367.60645.hdf5\n"
     ]
    }
   ],
   "source": [
    "nn_model = neural_network.fit(X_train_scaled, y_train,validation_split=0.3, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "2f1782df-dd01-453f-bd9e-97bc0af57c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for shallow net\n",
    "plt.plot(nn_model.history[\"loss\"])\n",
    "plt.plot(nn_model.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - 1 hidden layer\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "f2b8a39f-a7de-4084-9b69-281d5f05bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to define the number of hidden nodes and input features\n",
    "# start with a shallow network and expand from there\n",
    "# I am going to start with the number of columns as the input features\n",
    "number_input_columns_2 = X.shape[1]\n",
    "number_hidden_nodes_2 = (X.shape[1]/2)\n",
    "hidden_layer_3 = (number_hidden_nodes_2/2)\n",
    "hidden_layer_4 = (hidden_layer_3/2)\n",
    "\n",
    "# Create NN\n",
    "neural_network_2 = Sequential()\n",
    "\n",
    "# create the hidden latter\n",
    "neural_network_2.add(Dense(units = number_hidden_nodes, input_dim = number_input_columns, activation = \"relu\", kernel_initializer='normal' ))\n",
    "# create second hidden layer\n",
    "#neural_network_2.add(Dense(units = number_hidden_nodes_2,  activation = \"relu\", kernel_initializer='normal'))\n",
    "# hidden layer 3\n",
    "#neural_network_2.add(Dense(units = hidden_layer_3,  activation = \"relu\", kernel_initializer='normal'))\n",
    "# hidden layer 4\n",
    "#neural_network_2.add(Dense(units = hidden_layer_4,  activation = \"relu\", kernel_initializer='normal'))\n",
    "#output layer\n",
    "neural_network_2.add(Dense(units =number_hidden_nodes_2,  activation = \"relu\", kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "7ca879c7-0068-40d9-855f-85005a0ead0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210.0"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_hidden_nodes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "33e07944-d26d-4310-b59b-fd463e4ef467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_input_columns_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "32342e8e-e66d-423e-a55f-60754787e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 210)               88410     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 210)               44310     \n",
      "=================================================================\n",
      "Total params: 132,720\n",
      "Trainable params: 132,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neural_network_2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "neural_network_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "82596ebb-21b1-4e4e-9ff0-30483756a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6931.8013 - mean_absolute_error: 6931.8013 - val_loss: 9519.4014 - val_mean_absolute_error: 9519.4014\n",
      "Epoch 2/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6917.3096 - mean_absolute_error: 6917.3096 - val_loss: 9515.4189 - val_mean_absolute_error: 9515.4189\n",
      "Epoch 3/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6900.3403 - mean_absolute_error: 6900.3403 - val_loss: 9508.6738 - val_mean_absolute_error: 9508.6738\n",
      "Epoch 4/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6883.6968 - mean_absolute_error: 6883.6968 - val_loss: 9504.8438 - val_mean_absolute_error: 9504.8438\n",
      "Epoch 5/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6867.6650 - mean_absolute_error: 6867.6650 - val_loss: 9498.2910 - val_mean_absolute_error: 9498.2910\n",
      "Epoch 6/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6852.7764 - mean_absolute_error: 6852.7764 - val_loss: 9496.6631 - val_mean_absolute_error: 9496.6631\n",
      "Epoch 7/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6834.3589 - mean_absolute_error: 6834.3589 - val_loss: 9487.6689 - val_mean_absolute_error: 9487.6689\n",
      "Epoch 8/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6818.4810 - mean_absolute_error: 6818.4810 - val_loss: 9487.2422 - val_mean_absolute_error: 9487.2422\n",
      "Epoch 9/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6803.9746 - mean_absolute_error: 6803.9746 - val_loss: 9481.0303 - val_mean_absolute_error: 9481.0303\n",
      "Epoch 10/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6789.4224 - mean_absolute_error: 6789.4224 - val_loss: 9478.1465 - val_mean_absolute_error: 9478.1465\n",
      "Epoch 11/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6772.7524 - mean_absolute_error: 6772.7524 - val_loss: 9472.3311 - val_mean_absolute_error: 9472.3311\n",
      "Epoch 12/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6756.4536 - mean_absolute_error: 6756.4536 - val_loss: 9466.9023 - val_mean_absolute_error: 9466.9023\n",
      "Epoch 13/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6742.5059 - mean_absolute_error: 6742.5059 - val_loss: 9461.7773 - val_mean_absolute_error: 9461.7773\n",
      "Epoch 14/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6726.2886 - mean_absolute_error: 6726.2886 - val_loss: 9459.2324 - val_mean_absolute_error: 9459.2324\n",
      "Epoch 15/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6711.4282 - mean_absolute_error: 6711.4282 - val_loss: 9454.4199 - val_mean_absolute_error: 9454.4199\n",
      "Epoch 16/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6695.9175 - mean_absolute_error: 6695.9175 - val_loss: 9451.6016 - val_mean_absolute_error: 9451.6016\n",
      "Epoch 17/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6680.9214 - mean_absolute_error: 6680.9214 - val_loss: 9446.9355 - val_mean_absolute_error: 9446.9355\n",
      "Epoch 18/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6667.3438 - mean_absolute_error: 6667.3438 - val_loss: 9442.0967 - val_mean_absolute_error: 9442.0967\n",
      "Epoch 19/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6652.9404 - mean_absolute_error: 6652.9404 - val_loss: 9438.9834 - val_mean_absolute_error: 9438.9834\n",
      "Epoch 20/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6639.5527 - mean_absolute_error: 6639.5527 - val_loss: 9435.9648 - val_mean_absolute_error: 9435.9648\n",
      "Epoch 21/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6624.0815 - mean_absolute_error: 6624.0815 - val_loss: 9433.5156 - val_mean_absolute_error: 9433.5156\n",
      "Epoch 22/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6611.8105 - mean_absolute_error: 6611.8105 - val_loss: 9428.5986 - val_mean_absolute_error: 9428.5986\n",
      "Epoch 23/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6598.1587 - mean_absolute_error: 6598.1587 - val_loss: 9425.7725 - val_mean_absolute_error: 9425.7725\n",
      "Epoch 24/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6584.1304 - mean_absolute_error: 6584.1304 - val_loss: 9422.2080 - val_mean_absolute_error: 9422.2080\n",
      "Epoch 25/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6571.2642 - mean_absolute_error: 6571.2642 - val_loss: 9416.8662 - val_mean_absolute_error: 9416.8662\n",
      "Epoch 26/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6559.2212 - mean_absolute_error: 6559.2212 - val_loss: 9415.9160 - val_mean_absolute_error: 9415.9160\n",
      "Epoch 27/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6545.2993 - mean_absolute_error: 6545.2993 - val_loss: 9415.2666 - val_mean_absolute_error: 9415.2666\n",
      "Epoch 28/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6532.1357 - mean_absolute_error: 6532.1357 - val_loss: 9411.0664 - val_mean_absolute_error: 9411.0664\n",
      "Epoch 29/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6519.0483 - mean_absolute_error: 6519.0483 - val_loss: 9409.8740 - val_mean_absolute_error: 9409.8740\n",
      "Epoch 30/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6505.9194 - mean_absolute_error: 6505.9194 - val_loss: 9402.7441 - val_mean_absolute_error: 9402.7441\n",
      "Epoch 31/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6493.0688 - mean_absolute_error: 6493.0688 - val_loss: 9399.7119 - val_mean_absolute_error: 9399.7119\n",
      "Epoch 32/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6480.2759 - mean_absolute_error: 6480.2759 - val_loss: 9396.1738 - val_mean_absolute_error: 9396.1738\n",
      "Epoch 33/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6466.9727 - mean_absolute_error: 6466.9727 - val_loss: 9395.6943 - val_mean_absolute_error: 9395.6943\n",
      "Epoch 34/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6453.9741 - mean_absolute_error: 6453.9741 - val_loss: 9392.3662 - val_mean_absolute_error: 9392.3662\n",
      "Epoch 35/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6440.8003 - mean_absolute_error: 6440.8003 - val_loss: 9389.8389 - val_mean_absolute_error: 9389.8389\n",
      "Epoch 36/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6430.9727 - mean_absolute_error: 6430.9727 - val_loss: 9384.9062 - val_mean_absolute_error: 9384.9062\n",
      "Epoch 37/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6416.4854 - mean_absolute_error: 6416.4854 - val_loss: 9383.6367 - val_mean_absolute_error: 9383.6367\n",
      "Epoch 38/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6404.2866 - mean_absolute_error: 6404.2866 - val_loss: 9381.2988 - val_mean_absolute_error: 9381.2988\n",
      "Epoch 39/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6393.4521 - mean_absolute_error: 6393.4521 - val_loss: 9377.4170 - val_mean_absolute_error: 9377.4170\n",
      "Epoch 40/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6380.5317 - mean_absolute_error: 6380.5317 - val_loss: 9378.7607 - val_mean_absolute_error: 9378.7607\n",
      "Epoch 41/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6368.5376 - mean_absolute_error: 6368.5376 - val_loss: 9374.1270 - val_mean_absolute_error: 9374.1270\n",
      "Epoch 42/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6356.9160 - mean_absolute_error: 6356.9160 - val_loss: 9371.1240 - val_mean_absolute_error: 9371.1240\n",
      "Epoch 43/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6344.3833 - mean_absolute_error: 6344.3833 - val_loss: 9368.8359 - val_mean_absolute_error: 9368.8359\n",
      "Epoch 44/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6331.9868 - mean_absolute_error: 6331.9868 - val_loss: 9363.9033 - val_mean_absolute_error: 9363.9033\n",
      "Epoch 45/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6321.1016 - mean_absolute_error: 6321.1016 - val_loss: 9362.6553 - val_mean_absolute_error: 9362.6553\n",
      "Epoch 46/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6309.1987 - mean_absolute_error: 6309.1987 - val_loss: 9359.7842 - val_mean_absolute_error: 9359.7842\n",
      "Epoch 47/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6295.9512 - mean_absolute_error: 6295.9512 - val_loss: 9357.7256 - val_mean_absolute_error: 9357.7256\n",
      "Epoch 48/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6285.3784 - mean_absolute_error: 6285.3784 - val_loss: 9353.8086 - val_mean_absolute_error: 9353.8086\n",
      "Epoch 49/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6273.5942 - mean_absolute_error: 6273.5942 - val_loss: 9350.7891 - val_mean_absolute_error: 9350.7891\n",
      "Epoch 50/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6263.4878 - mean_absolute_error: 6263.4878 - val_loss: 9350.2080 - val_mean_absolute_error: 9350.2080\n",
      "Epoch 51/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6252.7588 - mean_absolute_error: 6252.7588 - val_loss: 9345.9307 - val_mean_absolute_error: 9345.9307\n",
      "Epoch 52/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6239.8691 - mean_absolute_error: 6239.8691 - val_loss: 9344.8086 - val_mean_absolute_error: 9344.8086\n",
      "Epoch 53/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6228.5942 - mean_absolute_error: 6228.5942 - val_loss: 9341.9736 - val_mean_absolute_error: 9341.9736\n",
      "Epoch 54/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6219.1074 - mean_absolute_error: 6219.1074 - val_loss: 9340.1914 - val_mean_absolute_error: 9340.1914\n",
      "Epoch 55/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6208.0098 - mean_absolute_error: 6208.0098 - val_loss: 9337.5518 - val_mean_absolute_error: 9337.5518\n",
      "Epoch 56/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6196.9839 - mean_absolute_error: 6196.9839 - val_loss: 9335.7451 - val_mean_absolute_error: 9335.7451\n",
      "Epoch 57/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6185.4351 - mean_absolute_error: 6185.4351 - val_loss: 9332.8516 - val_mean_absolute_error: 9332.8516\n",
      "Epoch 58/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6174.3257 - mean_absolute_error: 6174.3257 - val_loss: 9329.4805 - val_mean_absolute_error: 9329.4805\n",
      "Epoch 59/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6163.2988 - mean_absolute_error: 6163.2988 - val_loss: 9326.7588 - val_mean_absolute_error: 9326.7588\n",
      "Epoch 60/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6151.9087 - mean_absolute_error: 6151.9087 - val_loss: 9323.1133 - val_mean_absolute_error: 9323.1133\n",
      "Epoch 61/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6141.8857 - mean_absolute_error: 6141.8857 - val_loss: 9322.7256 - val_mean_absolute_error: 9322.7256\n",
      "Epoch 62/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6129.3506 - mean_absolute_error: 6129.3506 - val_loss: 9317.3223 - val_mean_absolute_error: 9317.3223\n",
      "Epoch 63/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6119.7642 - mean_absolute_error: 6119.7642 - val_loss: 9315.7197 - val_mean_absolute_error: 9315.7197\n",
      "Epoch 64/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6108.7075 - mean_absolute_error: 6108.7075 - val_loss: 9314.8213 - val_mean_absolute_error: 9314.8213\n",
      "Epoch 65/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6098.9727 - mean_absolute_error: 6098.9727 - val_loss: 9312.3340 - val_mean_absolute_error: 9312.3340\n",
      "Epoch 66/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6087.1011 - mean_absolute_error: 6087.1011 - val_loss: 9308.2686 - val_mean_absolute_error: 9308.2686\n",
      "Epoch 67/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6077.4067 - mean_absolute_error: 6077.4067 - val_loss: 9305.7676 - val_mean_absolute_error: 9305.7676\n",
      "Epoch 68/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6064.9951 - mean_absolute_error: 6064.9951 - val_loss: 9304.7793 - val_mean_absolute_error: 9304.7793\n",
      "Epoch 69/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6055.9507 - mean_absolute_error: 6055.9507 - val_loss: 9300.7510 - val_mean_absolute_error: 9300.7510\n",
      "Epoch 70/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6044.9775 - mean_absolute_error: 6044.9775 - val_loss: 9299.2451 - val_mean_absolute_error: 9299.2451\n",
      "Epoch 71/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 6032.5273 - mean_absolute_error: 6032.5273 - val_loss: 9297.3652 - val_mean_absolute_error: 9297.3652\n",
      "Epoch 72/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6022.7778 - mean_absolute_error: 6022.7778 - val_loss: 9293.0791 - val_mean_absolute_error: 9293.0791\n",
      "Epoch 73/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6013.6646 - mean_absolute_error: 6013.6646 - val_loss: 9291.0957 - val_mean_absolute_error: 9291.0957\n",
      "Epoch 74/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 6002.9258 - mean_absolute_error: 6002.9258 - val_loss: 9290.7930 - val_mean_absolute_error: 9290.7930\n",
      "Epoch 75/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5992.8721 - mean_absolute_error: 5992.8721 - val_loss: 9289.5215 - val_mean_absolute_error: 9289.5215\n",
      "Epoch 76/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5980.9829 - mean_absolute_error: 5980.9829 - val_loss: 9284.1855 - val_mean_absolute_error: 9284.1855\n",
      "Epoch 77/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5971.0737 - mean_absolute_error: 5971.0737 - val_loss: 9281.9121 - val_mean_absolute_error: 9281.9121\n",
      "Epoch 78/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5961.8945 - mean_absolute_error: 5961.8945 - val_loss: 9278.3838 - val_mean_absolute_error: 9278.3838\n",
      "Epoch 79/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5950.7104 - mean_absolute_error: 5950.7104 - val_loss: 9277.1895 - val_mean_absolute_error: 9277.1895\n",
      "Epoch 80/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5939.6260 - mean_absolute_error: 5939.6260 - val_loss: 9276.4863 - val_mean_absolute_error: 9276.4863\n",
      "Epoch 81/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5929.3594 - mean_absolute_error: 5929.3594 - val_loss: 9273.9385 - val_mean_absolute_error: 9273.9385\n",
      "Epoch 82/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5918.9575 - mean_absolute_error: 5918.9575 - val_loss: 9274.2158 - val_mean_absolute_error: 9274.2158\n",
      "Epoch 83/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5908.9951 - mean_absolute_error: 5908.9951 - val_loss: 9273.2783 - val_mean_absolute_error: 9273.2783\n",
      "Epoch 84/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5899.5288 - mean_absolute_error: 5899.5288 - val_loss: 9272.2285 - val_mean_absolute_error: 9272.2285\n",
      "Epoch 85/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5889.7490 - mean_absolute_error: 5889.7490 - val_loss: 9268.1211 - val_mean_absolute_error: 9268.1211\n",
      "Epoch 86/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5880.5967 - mean_absolute_error: 5880.5967 - val_loss: 9268.2686 - val_mean_absolute_error: 9268.2686\n",
      "Epoch 87/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5871.2666 - mean_absolute_error: 5871.2666 - val_loss: 9266.7412 - val_mean_absolute_error: 9266.7412\n",
      "Epoch 88/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5860.3945 - mean_absolute_error: 5860.3945 - val_loss: 9264.8047 - val_mean_absolute_error: 9264.8047\n",
      "Epoch 89/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5850.9619 - mean_absolute_error: 5850.9619 - val_loss: 9264.4727 - val_mean_absolute_error: 9264.4727\n",
      "Epoch 90/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5843.9702 - mean_absolute_error: 5843.9702 - val_loss: 9263.9092 - val_mean_absolute_error: 9263.9092\n",
      "Epoch 91/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5831.5566 - mean_absolute_error: 5831.5566 - val_loss: 9263.6514 - val_mean_absolute_error: 9263.6514\n",
      "Epoch 92/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5822.1523 - mean_absolute_error: 5822.1523 - val_loss: 9260.7393 - val_mean_absolute_error: 9260.7393\n",
      "Epoch 93/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5814.9849 - mean_absolute_error: 5814.9849 - val_loss: 9259.4219 - val_mean_absolute_error: 9259.4219\n",
      "Epoch 94/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5804.0449 - mean_absolute_error: 5804.0449 - val_loss: 9258.5752 - val_mean_absolute_error: 9258.5752\n",
      "Epoch 95/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5795.3525 - mean_absolute_error: 5795.3525 - val_loss: 9257.2979 - val_mean_absolute_error: 9257.2979\n",
      "Epoch 96/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5785.9321 - mean_absolute_error: 5785.9321 - val_loss: 9256.8701 - val_mean_absolute_error: 9256.8701\n",
      "Epoch 97/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5775.1875 - mean_absolute_error: 5775.1875 - val_loss: 9255.7471 - val_mean_absolute_error: 9255.7471\n",
      "Epoch 98/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5767.9634 - mean_absolute_error: 5767.9634 - val_loss: 9254.8770 - val_mean_absolute_error: 9254.8770\n",
      "Epoch 99/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5757.9468 - mean_absolute_error: 5757.9468 - val_loss: 9252.0635 - val_mean_absolute_error: 9252.0635\n",
      "Epoch 100/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5748.3711 - mean_absolute_error: 5748.3711 - val_loss: 9251.6055 - val_mean_absolute_error: 9251.6055\n",
      "Epoch 101/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5739.7280 - mean_absolute_error: 5739.7280 - val_loss: 9249.7988 - val_mean_absolute_error: 9249.7988\n",
      "Epoch 102/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5732.0542 - mean_absolute_error: 5732.0542 - val_loss: 9248.4531 - val_mean_absolute_error: 9248.4531\n",
      "Epoch 103/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5721.6704 - mean_absolute_error: 5721.6704 - val_loss: 9248.6846 - val_mean_absolute_error: 9248.6846\n",
      "Epoch 104/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5712.7715 - mean_absolute_error: 5712.7715 - val_loss: 9247.5020 - val_mean_absolute_error: 9247.5020\n",
      "Epoch 105/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5704.9585 - mean_absolute_error: 5704.9585 - val_loss: 9243.7471 - val_mean_absolute_error: 9243.7471\n",
      "Epoch 106/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5694.9121 - mean_absolute_error: 5694.9121 - val_loss: 9243.6162 - val_mean_absolute_error: 9243.6162\n",
      "Epoch 107/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5687.4175 - mean_absolute_error: 5687.4175 - val_loss: 9245.6904 - val_mean_absolute_error: 9245.6904\n",
      "Epoch 108/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5678.2031 - mean_absolute_error: 5678.2031 - val_loss: 9246.1914 - val_mean_absolute_error: 9246.1914\n",
      "Epoch 109/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5670.7026 - mean_absolute_error: 5670.7026 - val_loss: 9242.1465 - val_mean_absolute_error: 9242.1465\n",
      "Epoch 110/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5661.7324 - mean_absolute_error: 5661.7324 - val_loss: 9243.1592 - val_mean_absolute_error: 9243.1592\n",
      "Epoch 111/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5653.2217 - mean_absolute_error: 5653.2217 - val_loss: 9241.0010 - val_mean_absolute_error: 9241.0010\n",
      "Epoch 112/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5645.8081 - mean_absolute_error: 5645.8081 - val_loss: 9241.3252 - val_mean_absolute_error: 9241.3252\n",
      "Epoch 113/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5636.9868 - mean_absolute_error: 5636.9868 - val_loss: 9239.8184 - val_mean_absolute_error: 9239.8184\n",
      "Epoch 114/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5628.2632 - mean_absolute_error: 5628.2632 - val_loss: 9238.4971 - val_mean_absolute_error: 9238.4971\n",
      "Epoch 115/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5619.7842 - mean_absolute_error: 5619.7842 - val_loss: 9236.6426 - val_mean_absolute_error: 9236.6426\n",
      "Epoch 116/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5610.9121 - mean_absolute_error: 5610.9121 - val_loss: 9234.1885 - val_mean_absolute_error: 9234.1885\n",
      "Epoch 117/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5605.2202 - mean_absolute_error: 5605.2202 - val_loss: 9236.2080 - val_mean_absolute_error: 9236.2080\n",
      "Epoch 118/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5594.7695 - mean_absolute_error: 5594.7695 - val_loss: 9233.3799 - val_mean_absolute_error: 9233.3799\n",
      "Epoch 119/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5586.0439 - mean_absolute_error: 5586.0439 - val_loss: 9233.1113 - val_mean_absolute_error: 9233.1113\n",
      "Epoch 120/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5580.0356 - mean_absolute_error: 5580.0356 - val_loss: 9232.3330 - val_mean_absolute_error: 9232.3330\n",
      "Epoch 121/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5570.6851 - mean_absolute_error: 5570.6851 - val_loss: 9231.6641 - val_mean_absolute_error: 9231.6641\n",
      "Epoch 122/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5562.9805 - mean_absolute_error: 5562.9805 - val_loss: 9231.5996 - val_mean_absolute_error: 9231.5996\n",
      "Epoch 123/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5556.6099 - mean_absolute_error: 5556.6099 - val_loss: 9228.8379 - val_mean_absolute_error: 9228.8379\n",
      "Epoch 124/300\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5545.9277 - mean_absolute_error: 5545.9277 - val_loss: 9228.0381 - val_mean_absolute_error: 9228.0381\n",
      "Epoch 125/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5538.8169 - mean_absolute_error: 5538.8169 - val_loss: 9228.2998 - val_mean_absolute_error: 9228.2998\n",
      "Epoch 126/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5531.2422 - mean_absolute_error: 5531.2422 - val_loss: 9227.0596 - val_mean_absolute_error: 9227.0596\n",
      "Epoch 127/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5523.4297 - mean_absolute_error: 5523.4297 - val_loss: 9226.2949 - val_mean_absolute_error: 9226.2949\n",
      "Epoch 128/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5515.3462 - mean_absolute_error: 5515.3462 - val_loss: 9225.0811 - val_mean_absolute_error: 9225.0811\n",
      "Epoch 129/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5508.3120 - mean_absolute_error: 5508.3120 - val_loss: 9224.0586 - val_mean_absolute_error: 9224.0586\n",
      "Epoch 130/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5499.7871 - mean_absolute_error: 5499.7871 - val_loss: 9221.7412 - val_mean_absolute_error: 9221.7412\n",
      "Epoch 131/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5491.3569 - mean_absolute_error: 5491.3569 - val_loss: 9221.6006 - val_mean_absolute_error: 9221.6006\n",
      "Epoch 132/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5484.4688 - mean_absolute_error: 5484.4688 - val_loss: 9221.4492 - val_mean_absolute_error: 9221.4492\n",
      "Epoch 133/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5476.4351 - mean_absolute_error: 5476.4351 - val_loss: 9221.5068 - val_mean_absolute_error: 9221.5068\n",
      "Epoch 134/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5468.8125 - mean_absolute_error: 5468.8125 - val_loss: 9219.3271 - val_mean_absolute_error: 9219.3271\n",
      "Epoch 135/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5461.1069 - mean_absolute_error: 5461.1069 - val_loss: 9219.4404 - val_mean_absolute_error: 9219.4404\n",
      "Epoch 136/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5453.9131 - mean_absolute_error: 5453.9131 - val_loss: 9220.4648 - val_mean_absolute_error: 9220.4648\n",
      "Epoch 137/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5446.4312 - mean_absolute_error: 5446.4312 - val_loss: 9217.2168 - val_mean_absolute_error: 9217.2168\n",
      "Epoch 138/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5439.5464 - mean_absolute_error: 5439.5464 - val_loss: 9217.6289 - val_mean_absolute_error: 9217.6289\n",
      "Epoch 139/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5430.8931 - mean_absolute_error: 5430.8931 - val_loss: 9217.5400 - val_mean_absolute_error: 9217.5400\n",
      "Epoch 140/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5424.2559 - mean_absolute_error: 5424.2559 - val_loss: 9216.5029 - val_mean_absolute_error: 9216.5029\n",
      "Epoch 141/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5415.7349 - mean_absolute_error: 5415.7349 - val_loss: 9213.6484 - val_mean_absolute_error: 9213.6484\n",
      "Epoch 142/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5408.8169 - mean_absolute_error: 5408.8169 - val_loss: 9214.5596 - val_mean_absolute_error: 9214.5596\n",
      "Epoch 143/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5400.2158 - mean_absolute_error: 5400.2158 - val_loss: 9213.8545 - val_mean_absolute_error: 9213.8545\n",
      "Epoch 144/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5394.1265 - mean_absolute_error: 5394.1265 - val_loss: 9210.9834 - val_mean_absolute_error: 9210.9834\n",
      "Epoch 145/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5389.7466 - mean_absolute_error: 5389.7466 - val_loss: 9211.2051 - val_mean_absolute_error: 9211.2051\n",
      "Epoch 146/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5379.3931 - mean_absolute_error: 5379.3931 - val_loss: 9211.7500 - val_mean_absolute_error: 9211.7500\n",
      "Epoch 147/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5373.3481 - mean_absolute_error: 5373.3481 - val_loss: 9211.2969 - val_mean_absolute_error: 9211.2969\n",
      "Epoch 148/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5366.0352 - mean_absolute_error: 5366.0352 - val_loss: 9212.4287 - val_mean_absolute_error: 9212.4287\n",
      "Epoch 149/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5358.9370 - mean_absolute_error: 5358.9370 - val_loss: 9211.1055 - val_mean_absolute_error: 9211.1055\n",
      "Epoch 150/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5351.9810 - mean_absolute_error: 5351.9810 - val_loss: 9211.0645 - val_mean_absolute_error: 9211.0645\n",
      "Epoch 151/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5344.1055 - mean_absolute_error: 5344.1055 - val_loss: 9211.7383 - val_mean_absolute_error: 9211.7383\n",
      "Epoch 152/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5339.0078 - mean_absolute_error: 5339.0078 - val_loss: 9211.4170 - val_mean_absolute_error: 9211.4170\n",
      "Epoch 153/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5330.9175 - mean_absolute_error: 5330.9175 - val_loss: 9211.7148 - val_mean_absolute_error: 9211.7148\n",
      "Epoch 154/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5322.1396 - mean_absolute_error: 5322.1396 - val_loss: 9211.5371 - val_mean_absolute_error: 9211.5371\n",
      "Epoch 155/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5315.9946 - mean_absolute_error: 5315.9946 - val_loss: 9211.4736 - val_mean_absolute_error: 9211.4736\n",
      "Epoch 156/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5309.5742 - mean_absolute_error: 5309.5742 - val_loss: 9211.0361 - val_mean_absolute_error: 9211.0361\n",
      "Epoch 157/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5301.4741 - mean_absolute_error: 5301.4741 - val_loss: 9211.2031 - val_mean_absolute_error: 9211.2031\n",
      "Epoch 158/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5295.4688 - mean_absolute_error: 5295.4688 - val_loss: 9211.3623 - val_mean_absolute_error: 9211.3623\n",
      "Epoch 159/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5289.3794 - mean_absolute_error: 5289.3794 - val_loss: 9210.5449 - val_mean_absolute_error: 9210.5449\n",
      "Epoch 160/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5282.2485 - mean_absolute_error: 5282.2485 - val_loss: 9210.8516 - val_mean_absolute_error: 9210.8516\n",
      "Epoch 161/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5275.2842 - mean_absolute_error: 5275.2842 - val_loss: 9212.1230 - val_mean_absolute_error: 9212.1230\n",
      "Epoch 162/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5267.3296 - mean_absolute_error: 5267.3296 - val_loss: 9209.1592 - val_mean_absolute_error: 9209.1592\n",
      "Epoch 163/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5260.5107 - mean_absolute_error: 5260.5107 - val_loss: 9210.1152 - val_mean_absolute_error: 9210.1152\n",
      "Epoch 164/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5253.8843 - mean_absolute_error: 5253.8843 - val_loss: 9210.1807 - val_mean_absolute_error: 9210.1807\n",
      "Epoch 165/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5247.2114 - mean_absolute_error: 5247.2114 - val_loss: 9209.2158 - val_mean_absolute_error: 9209.2158\n",
      "Epoch 166/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5240.6812 - mean_absolute_error: 5240.6812 - val_loss: 9209.6172 - val_mean_absolute_error: 9209.6172\n",
      "Epoch 167/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5234.1914 - mean_absolute_error: 5234.1914 - val_loss: 9210.1855 - val_mean_absolute_error: 9210.1855\n",
      "Epoch 168/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5227.1841 - mean_absolute_error: 5227.1841 - val_loss: 9212.0645 - val_mean_absolute_error: 9212.0645\n",
      "Epoch 169/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5220.8613 - mean_absolute_error: 5220.8613 - val_loss: 9208.9668 - val_mean_absolute_error: 9208.9668\n",
      "Epoch 170/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5213.1289 - mean_absolute_error: 5213.1289 - val_loss: 9209.6416 - val_mean_absolute_error: 9209.6416\n",
      "Epoch 171/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5209.4585 - mean_absolute_error: 5209.4585 - val_loss: 9207.4912 - val_mean_absolute_error: 9207.4912\n",
      "Epoch 172/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5199.9067 - mean_absolute_error: 5199.9067 - val_loss: 9210.5723 - val_mean_absolute_error: 9210.5723\n",
      "Epoch 173/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5193.7222 - mean_absolute_error: 5193.7222 - val_loss: 9207.8477 - val_mean_absolute_error: 9207.8477\n",
      "Epoch 174/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5188.6494 - mean_absolute_error: 5188.6494 - val_loss: 9209.6309 - val_mean_absolute_error: 9209.6309\n",
      "Epoch 175/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5182.6377 - mean_absolute_error: 5182.6377 - val_loss: 9209.1865 - val_mean_absolute_error: 9209.1865\n",
      "Epoch 176/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5174.9800 - mean_absolute_error: 5174.9800 - val_loss: 9208.6631 - val_mean_absolute_error: 9208.6631\n",
      "Epoch 177/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5168.4668 - mean_absolute_error: 5168.4668 - val_loss: 9209.5508 - val_mean_absolute_error: 9209.5508\n",
      "Epoch 178/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5162.2646 - mean_absolute_error: 5162.2646 - val_loss: 9209.9590 - val_mean_absolute_error: 9209.9590\n",
      "Epoch 179/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5156.0986 - mean_absolute_error: 5156.0986 - val_loss: 9212.2559 - val_mean_absolute_error: 9212.2559\n",
      "Epoch 180/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5150.0386 - mean_absolute_error: 5150.0386 - val_loss: 9208.7910 - val_mean_absolute_error: 9208.7910\n",
      "Epoch 181/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5145.2593 - mean_absolute_error: 5145.2593 - val_loss: 9209.2256 - val_mean_absolute_error: 9209.2256\n",
      "Epoch 182/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5137.6021 - mean_absolute_error: 5137.6021 - val_loss: 9210.2285 - val_mean_absolute_error: 9210.2285\n",
      "Epoch 183/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5131.0640 - mean_absolute_error: 5131.0640 - val_loss: 9213.3887 - val_mean_absolute_error: 9213.3887\n",
      "Epoch 184/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5125.5210 - mean_absolute_error: 5125.5210 - val_loss: 9211.7871 - val_mean_absolute_error: 9211.7871\n",
      "Epoch 185/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5119.2905 - mean_absolute_error: 5119.2905 - val_loss: 9212.8359 - val_mean_absolute_error: 9212.8359\n",
      "Epoch 186/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5112.9224 - mean_absolute_error: 5112.9224 - val_loss: 9211.9551 - val_mean_absolute_error: 9211.9551\n",
      "Epoch 187/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5107.1133 - mean_absolute_error: 5107.1133 - val_loss: 9210.5547 - val_mean_absolute_error: 9210.5547\n",
      "Epoch 188/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5101.3423 - mean_absolute_error: 5101.3423 - val_loss: 9212.9277 - val_mean_absolute_error: 9212.9277\n",
      "Epoch 189/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5095.0229 - mean_absolute_error: 5095.0229 - val_loss: 9213.8887 - val_mean_absolute_error: 9213.8887\n",
      "Epoch 190/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 5088.9761 - mean_absolute_error: 5088.9761 - val_loss: 9212.1553 - val_mean_absolute_error: 9212.1553\n",
      "Epoch 191/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5082.4521 - mean_absolute_error: 5082.4521 - val_loss: 9213.1611 - val_mean_absolute_error: 9213.1611\n",
      "Epoch 192/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5076.7271 - mean_absolute_error: 5076.7271 - val_loss: 9213.8574 - val_mean_absolute_error: 9213.8574\n",
      "Epoch 193/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5071.9683 - mean_absolute_error: 5071.9683 - val_loss: 9212.5918 - val_mean_absolute_error: 9212.5918\n",
      "Epoch 194/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5066.3311 - mean_absolute_error: 5066.3311 - val_loss: 9214.5879 - val_mean_absolute_error: 9214.5879\n",
      "Epoch 195/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5058.2930 - mean_absolute_error: 5058.2930 - val_loss: 9214.5488 - val_mean_absolute_error: 9214.5488\n",
      "Epoch 196/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5053.0796 - mean_absolute_error: 5053.0796 - val_loss: 9214.6338 - val_mean_absolute_error: 9214.6338\n",
      "Epoch 197/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5047.6577 - mean_absolute_error: 5047.6577 - val_loss: 9216.2207 - val_mean_absolute_error: 9216.2207\n",
      "Epoch 198/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5042.3486 - mean_absolute_error: 5042.3486 - val_loss: 9215.0117 - val_mean_absolute_error: 9215.0117\n",
      "Epoch 199/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5037.1880 - mean_absolute_error: 5037.1880 - val_loss: 9215.4648 - val_mean_absolute_error: 9215.4648\n",
      "Epoch 200/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5030.8774 - mean_absolute_error: 5030.8774 - val_loss: 9215.3174 - val_mean_absolute_error: 9215.3174\n",
      "Epoch 201/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5024.8350 - mean_absolute_error: 5024.8350 - val_loss: 9217.9277 - val_mean_absolute_error: 9217.9277\n",
      "Epoch 202/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5018.8584 - mean_absolute_error: 5018.8584 - val_loss: 9215.4238 - val_mean_absolute_error: 9215.4238\n",
      "Epoch 203/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5014.0664 - mean_absolute_error: 5014.0664 - val_loss: 9218.0938 - val_mean_absolute_error: 9218.0938\n",
      "Epoch 204/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5008.3755 - mean_absolute_error: 5008.3755 - val_loss: 9217.4072 - val_mean_absolute_error: 9217.4072\n",
      "Epoch 205/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5002.5220 - mean_absolute_error: 5002.5220 - val_loss: 9215.7129 - val_mean_absolute_error: 9215.7129\n",
      "Epoch 206/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4996.9531 - mean_absolute_error: 4996.9531 - val_loss: 9218.3184 - val_mean_absolute_error: 9218.3184\n",
      "Epoch 207/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4990.5161 - mean_absolute_error: 4990.5161 - val_loss: 9216.9951 - val_mean_absolute_error: 9216.9951\n",
      "Epoch 208/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4987.6201 - mean_absolute_error: 4987.6201 - val_loss: 9218.6631 - val_mean_absolute_error: 9218.6631\n",
      "Epoch 209/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4978.0459 - mean_absolute_error: 4978.0459 - val_loss: 9218.7100 - val_mean_absolute_error: 9218.7100\n",
      "Epoch 210/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4974.6792 - mean_absolute_error: 4974.6792 - val_loss: 9217.6055 - val_mean_absolute_error: 9217.6055\n",
      "Epoch 211/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4968.7412 - mean_absolute_error: 4968.7412 - val_loss: 9218.0596 - val_mean_absolute_error: 9218.0596\n",
      "Epoch 212/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4961.0239 - mean_absolute_error: 4961.0239 - val_loss: 9219.5820 - val_mean_absolute_error: 9219.5820\n",
      "Epoch 213/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4957.9058 - mean_absolute_error: 4957.9058 - val_loss: 9220.3174 - val_mean_absolute_error: 9220.3174\n",
      "Epoch 214/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4951.5942 - mean_absolute_error: 4951.5942 - val_loss: 9218.5410 - val_mean_absolute_error: 9218.5410\n",
      "Epoch 215/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4946.7505 - mean_absolute_error: 4946.7505 - val_loss: 9220.1338 - val_mean_absolute_error: 9220.1338\n",
      "Epoch 216/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4941.5205 - mean_absolute_error: 4941.5205 - val_loss: 9220.2666 - val_mean_absolute_error: 9220.2666\n",
      "Epoch 217/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4935.8042 - mean_absolute_error: 4935.8042 - val_loss: 9220.1143 - val_mean_absolute_error: 9220.1143\n",
      "Epoch 218/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4930.4512 - mean_absolute_error: 4930.4512 - val_loss: 9220.5547 - val_mean_absolute_error: 9220.5547\n",
      "Epoch 219/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4925.5063 - mean_absolute_error: 4925.5063 - val_loss: 9219.2207 - val_mean_absolute_error: 9219.2207\n",
      "Epoch 220/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4919.4150 - mean_absolute_error: 4919.4150 - val_loss: 9221.9033 - val_mean_absolute_error: 9221.9033\n",
      "Epoch 221/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4915.3467 - mean_absolute_error: 4915.3467 - val_loss: 9222.3301 - val_mean_absolute_error: 9222.3301\n",
      "Epoch 222/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4909.9038 - mean_absolute_error: 4909.9038 - val_loss: 9221.8291 - val_mean_absolute_error: 9221.8291\n",
      "Epoch 223/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4904.2334 - mean_absolute_error: 4904.2334 - val_loss: 9220.4092 - val_mean_absolute_error: 9220.4092\n",
      "Epoch 224/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4898.4277 - mean_absolute_error: 4898.4277 - val_loss: 9222.6914 - val_mean_absolute_error: 9222.6914\n",
      "Epoch 225/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4893.7847 - mean_absolute_error: 4893.7847 - val_loss: 9219.7051 - val_mean_absolute_error: 9219.7051\n",
      "Epoch 226/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4887.7866 - mean_absolute_error: 4887.7866 - val_loss: 9221.4336 - val_mean_absolute_error: 9221.4336\n",
      "Epoch 227/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4882.5083 - mean_absolute_error: 4882.5083 - val_loss: 9221.9395 - val_mean_absolute_error: 9221.9395\n",
      "Epoch 228/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4878.5439 - mean_absolute_error: 4878.5439 - val_loss: 9222.3418 - val_mean_absolute_error: 9222.3418\n",
      "Epoch 229/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4871.4521 - mean_absolute_error: 4871.4521 - val_loss: 9223.4258 - val_mean_absolute_error: 9223.4258\n",
      "Epoch 230/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4866.5747 - mean_absolute_error: 4866.5747 - val_loss: 9220.9189 - val_mean_absolute_error: 9220.9189\n",
      "Epoch 231/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4859.5278 - mean_absolute_error: 4859.5278 - val_loss: 9223.2969 - val_mean_absolute_error: 9223.2969\n",
      "Epoch 232/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4856.7441 - mean_absolute_error: 4856.7441 - val_loss: 9223.5381 - val_mean_absolute_error: 9223.5381\n",
      "Epoch 233/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4850.8369 - mean_absolute_error: 4850.8369 - val_loss: 9221.2686 - val_mean_absolute_error: 9221.2686\n",
      "Epoch 234/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4846.1812 - mean_absolute_error: 4846.1812 - val_loss: 9221.3291 - val_mean_absolute_error: 9221.3291\n",
      "Epoch 235/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4841.0127 - mean_absolute_error: 4841.0127 - val_loss: 9224.4414 - val_mean_absolute_error: 9224.4414\n",
      "Epoch 236/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4834.8042 - mean_absolute_error: 4834.8042 - val_loss: 9223.1211 - val_mean_absolute_error: 9223.1211\n",
      "Epoch 237/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4830.4434 - mean_absolute_error: 4830.4434 - val_loss: 9220.9121 - val_mean_absolute_error: 9220.9121\n",
      "Epoch 238/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4824.5439 - mean_absolute_error: 4824.5439 - val_loss: 9225.9092 - val_mean_absolute_error: 9225.9092\n",
      "Epoch 239/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4820.7837 - mean_absolute_error: 4820.7837 - val_loss: 9225.3252 - val_mean_absolute_error: 9225.3252\n",
      "Epoch 240/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4813.4229 - mean_absolute_error: 4813.4229 - val_loss: 9222.0693 - val_mean_absolute_error: 9222.0693\n",
      "Epoch 241/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4809.0483 - mean_absolute_error: 4809.0483 - val_loss: 9223.8027 - val_mean_absolute_error: 9223.8027\n",
      "Epoch 242/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4806.5396 - mean_absolute_error: 4806.5396 - val_loss: 9221.4951 - val_mean_absolute_error: 9221.4951\n",
      "Epoch 243/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4799.4795 - mean_absolute_error: 4799.4795 - val_loss: 9224.9766 - val_mean_absolute_error: 9224.9766\n",
      "Epoch 244/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4796.7251 - mean_absolute_error: 4796.7251 - val_loss: 9224.1592 - val_mean_absolute_error: 9224.1592\n",
      "Epoch 245/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4789.9888 - mean_absolute_error: 4789.9888 - val_loss: 9223.9600 - val_mean_absolute_error: 9223.9600\n",
      "Epoch 246/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4784.2749 - mean_absolute_error: 4784.2749 - val_loss: 9227.2881 - val_mean_absolute_error: 9227.2881\n",
      "Epoch 247/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4781.0430 - mean_absolute_error: 4781.0430 - val_loss: 9226.7949 - val_mean_absolute_error: 9226.7949\n",
      "Epoch 248/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4775.3306 - mean_absolute_error: 4775.3306 - val_loss: 9225.7744 - val_mean_absolute_error: 9225.7744\n",
      "Epoch 249/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4769.3540 - mean_absolute_error: 4769.3540 - val_loss: 9227.6211 - val_mean_absolute_error: 9227.6211\n",
      "Epoch 250/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4763.1860 - mean_absolute_error: 4763.1860 - val_loss: 9225.5352 - val_mean_absolute_error: 9225.5352\n",
      "Epoch 251/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4760.0361 - mean_absolute_error: 4760.0361 - val_loss: 9227.1855 - val_mean_absolute_error: 9227.1855\n",
      "Epoch 252/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4755.5269 - mean_absolute_error: 4755.5269 - val_loss: 9225.9043 - val_mean_absolute_error: 9225.9043\n",
      "Epoch 253/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4749.8398 - mean_absolute_error: 4749.8398 - val_loss: 9230.8496 - val_mean_absolute_error: 9230.8496\n",
      "Epoch 254/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4744.5977 - mean_absolute_error: 4744.5977 - val_loss: 9230.1455 - val_mean_absolute_error: 9230.1455\n",
      "Epoch 255/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4738.7095 - mean_absolute_error: 4738.7095 - val_loss: 9229.3193 - val_mean_absolute_error: 9229.3193\n",
      "Epoch 256/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4734.6030 - mean_absolute_error: 4734.6030 - val_loss: 9231.4775 - val_mean_absolute_error: 9231.4775\n",
      "Epoch 257/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4728.5361 - mean_absolute_error: 4728.5361 - val_loss: 9232.1992 - val_mean_absolute_error: 9232.1992\n",
      "Epoch 258/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4724.8369 - mean_absolute_error: 4724.8369 - val_loss: 9229.7939 - val_mean_absolute_error: 9229.7939\n",
      "Epoch 259/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4719.5371 - mean_absolute_error: 4719.5371 - val_loss: 9233.0430 - val_mean_absolute_error: 9233.0430\n",
      "Epoch 260/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4713.6431 - mean_absolute_error: 4713.6431 - val_loss: 9233.9258 - val_mean_absolute_error: 9233.9258\n",
      "Epoch 261/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4709.9595 - mean_absolute_error: 4709.9595 - val_loss: 9230.8623 - val_mean_absolute_error: 9230.8623\n",
      "Epoch 262/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4703.4741 - mean_absolute_error: 4703.4741 - val_loss: 9233.0234 - val_mean_absolute_error: 9233.0234\n",
      "Epoch 263/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4700.2466 - mean_absolute_error: 4700.2466 - val_loss: 9232.4287 - val_mean_absolute_error: 9232.4287\n",
      "Epoch 264/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4693.3003 - mean_absolute_error: 4693.3003 - val_loss: 9232.1748 - val_mean_absolute_error: 9232.1748\n",
      "Epoch 265/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4689.8530 - mean_absolute_error: 4689.8530 - val_loss: 9237.1670 - val_mean_absolute_error: 9237.1670\n",
      "Epoch 266/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4683.6675 - mean_absolute_error: 4683.6675 - val_loss: 9235.6553 - val_mean_absolute_error: 9235.6553\n",
      "Epoch 267/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4680.1670 - mean_absolute_error: 4680.1670 - val_loss: 9237.0166 - val_mean_absolute_error: 9237.0166\n",
      "Epoch 268/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4675.0073 - mean_absolute_error: 4675.0073 - val_loss: 9237.5107 - val_mean_absolute_error: 9237.5107\n",
      "Epoch 269/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4670.1455 - mean_absolute_error: 4670.1455 - val_loss: 9238.2773 - val_mean_absolute_error: 9238.2773\n",
      "Epoch 270/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4666.1460 - mean_absolute_error: 4666.1460 - val_loss: 9239.0840 - val_mean_absolute_error: 9239.0840\n",
      "Epoch 271/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4660.2915 - mean_absolute_error: 4660.2915 - val_loss: 9237.5410 - val_mean_absolute_error: 9237.5410\n",
      "Epoch 272/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4656.8530 - mean_absolute_error: 4656.8530 - val_loss: 9237.0605 - val_mean_absolute_error: 9237.0605\n",
      "Epoch 273/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4653.1250 - mean_absolute_error: 4653.1250 - val_loss: 9239.7500 - val_mean_absolute_error: 9239.7500\n",
      "Epoch 274/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4644.7007 - mean_absolute_error: 4644.7007 - val_loss: 9239.8398 - val_mean_absolute_error: 9239.8398\n",
      "Epoch 275/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4640.9170 - mean_absolute_error: 4640.9170 - val_loss: 9239.7080 - val_mean_absolute_error: 9239.7080\n",
      "Epoch 276/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4638.2842 - mean_absolute_error: 4638.2842 - val_loss: 9239.9463 - val_mean_absolute_error: 9239.9463\n",
      "Epoch 277/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4632.8140 - mean_absolute_error: 4632.8140 - val_loss: 9238.3486 - val_mean_absolute_error: 9238.3486\n",
      "Epoch 278/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4626.8350 - mean_absolute_error: 4626.8350 - val_loss: 9241.4395 - val_mean_absolute_error: 9241.4395\n",
      "Epoch 279/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4623.4575 - mean_absolute_error: 4623.4575 - val_loss: 9242.8604 - val_mean_absolute_error: 9242.8604\n",
      "Epoch 280/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4619.8599 - mean_absolute_error: 4619.8599 - val_loss: 9241.9785 - val_mean_absolute_error: 9241.9785\n",
      "Epoch 281/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4613.7754 - mean_absolute_error: 4613.7754 - val_loss: 9242.8555 - val_mean_absolute_error: 9242.8555\n",
      "Epoch 282/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4609.0161 - mean_absolute_error: 4609.0161 - val_loss: 9244.2422 - val_mean_absolute_error: 9244.2422\n",
      "Epoch 283/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4604.2778 - mean_absolute_error: 4604.2778 - val_loss: 9242.3633 - val_mean_absolute_error: 9242.3633\n",
      "Epoch 284/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4600.1777 - mean_absolute_error: 4600.1777 - val_loss: 9244.7832 - val_mean_absolute_error: 9244.7832\n",
      "Epoch 285/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4593.7515 - mean_absolute_error: 4593.7515 - val_loss: 9247.2129 - val_mean_absolute_error: 9247.2129\n",
      "Epoch 286/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4588.8765 - mean_absolute_error: 4588.8765 - val_loss: 9246.8301 - val_mean_absolute_error: 9246.8301\n",
      "Epoch 287/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4585.6182 - mean_absolute_error: 4585.6182 - val_loss: 9246.4658 - val_mean_absolute_error: 9246.4658\n",
      "Epoch 288/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4580.0952 - mean_absolute_error: 4580.0952 - val_loss: 9246.9883 - val_mean_absolute_error: 9246.9883\n",
      "Epoch 289/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4577.0859 - mean_absolute_error: 4577.0859 - val_loss: 9247.3486 - val_mean_absolute_error: 9247.3486\n",
      "Epoch 290/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4571.4395 - mean_absolute_error: 4571.4395 - val_loss: 9246.0469 - val_mean_absolute_error: 9246.0469\n",
      "Epoch 291/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4568.4600 - mean_absolute_error: 4568.4600 - val_loss: 9247.5225 - val_mean_absolute_error: 9247.5225\n",
      "Epoch 292/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4564.3096 - mean_absolute_error: 4564.3096 - val_loss: 9247.7461 - val_mean_absolute_error: 9247.7461\n",
      "Epoch 293/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4558.7285 - mean_absolute_error: 4558.7285 - val_loss: 9250.5410 - val_mean_absolute_error: 9250.5410\n",
      "Epoch 294/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4554.8291 - mean_absolute_error: 4554.8291 - val_loss: 9247.8555 - val_mean_absolute_error: 9247.8555\n",
      "Epoch 295/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4548.2075 - mean_absolute_error: 4548.2075 - val_loss: 9251.1660 - val_mean_absolute_error: 9251.1660\n",
      "Epoch 296/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4546.9194 - mean_absolute_error: 4546.9194 - val_loss: 9251.1055 - val_mean_absolute_error: 9251.1055\n",
      "Epoch 297/300\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4541.9321 - mean_absolute_error: 4541.9321 - val_loss: 9251.3301 - val_mean_absolute_error: 9251.3301\n",
      "Epoch 298/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4537.3984 - mean_absolute_error: 4537.3984 - val_loss: 9250.7471 - val_mean_absolute_error: 9250.7471\n",
      "Epoch 299/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4531.4380 - mean_absolute_error: 4531.4380 - val_loss: 9253.1543 - val_mean_absolute_error: 9253.1543\n",
      "Epoch 300/300\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4527.2925 - mean_absolute_error: 4527.2925 - val_loss: 9251.8848 - val_mean_absolute_error: 9251.8848\n"
     ]
    }
   ],
   "source": [
    "nn_model_2 = neural_network_2.fit(X_train_scaled, y_train,validation_split=0.3, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "842b8f77-a2c6-43d0-946f-c47341b75bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for shallow net\n",
    "plt.plot(nn_model_2.history[\"loss\"])\n",
    "plt.plot(nn_model_2.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - 3 hidden layers\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d447fc-5bde-4f12-bd2f-1b5ba5d2a841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59157b3d-ba09-4bb9-9617-85ba7812fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9976c6-11ac-4358-a33d-6acf2488e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0e94e-8688-4afb-b951-ded308e91701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
